{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"di : pythonic dependency injection di is a modern dependency injection system, modeled around the simplicity of FastAPI's dependency injection. Key features: Intuitive : simple things are easy, complex things are possible. Succinct : declare what you want, and di figures out how to assmble it using type annotations. Correct : tested with MyPy: value: int = Depends(returns_str) gives an error. Flexible : with no fixed scopes, di can work within any framework, web or otherwise. Lifespans : di manages lifespans for dependencies by binding them to scopes. Caching : di caches values from dependencies to avoid duplicate computation. Scalability : di executes dependencies in parallel and only needs to solve them once. Performant : di moves sync dependencies into a threadpool to avoid blocking the event loop. Installation $ pip install di ---> 100% Warning This project is a work in progress. Until there is 1.X.Y release, expect breaking changes. Examples Simple Example Here is a simple example of how di works: from dataclasses import dataclass from di import Container , Dependant class A : ... class B : ... @dataclass class C : a : A b : B def main (): container = Container () c = container . execute_sync ( container . solve ( Dependant ( C ))) assert isinstance ( c , C ) assert isinstance ( c . a , A ) assert isinstance ( c . b , B ) Why do I need dependency injection in Python? Isn't that a Java thing? Dependency injection is a software architecture technique that helps us achieve inversion of control and dependency inversion (one of the five SOLID design principles). It is a common misconception that traditional software design principles do not apply to Python. As a matter of fact, you are probably using a lot of these techniques already! For example, the transport argument to httpx's Client ( docs ) is an excellent example of dependency injection. Most web frameworks employ inversion of control: when you define a view / controller, the web framework calls you! The same thing applies to CLIs (like click ) or TUIs (like Textual ). This is especially true for many newer webframeworks that not only use inversion of control but also dependency injection. Two great examples of this are FastAPI and BlackSheep . This project was born out of a desire to generalize and improve upon FastAPI's dependency injection system so that it can be used outside of FastAPI and even in other libraries. For a more comprehensive overview of Python projectes related to dependency injection, see Awesome Dependency Injection in Python . Project Aims This project aims to be a general dependency injection system, with a focus on providing the underlaying dependency injection functionality for other libaries. In other words, while you could use this as your a standalone dependency injection framework, you may find it to be a bit terse and verbose. There are also much more mature standalone dependency injection frameworks; I would recommend at least looking into python-dependency-injector since it is currently the most popular / widely used of the bunch. In-depth example With this background in place, let's dive into a more in-depth example. In this example, we'll look at what it would take for a web framework to provide dependecy injection to it's users via di . Let's start by looking at the User's code. from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) As a user, you have very little boilerplate. In fact, there is not a single line of code here that is not transmitting information. Now let's look at the web framework side of things. This part can get a bit complex, but it's okay because it's written once, in a library. First, we'll need to create a Container instance. This would be tied to the App or Router instance of the web framwork. from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) Next, we \"solve\" the users endpoint: from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) This should happen once, maybe at app startup. The framework can then store the solved object, which contains all of the information necessary to execute the dependency (dependency being in this case the user's endpoint/controller function). This is very important for performance: we want do the least amount of work possible for each incoming request. Finally, we execute the endpoint for each incoming request: from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) When we do this, we provide the Request instance as a value. This means that di does not introspect at all into the Request to figure out how to build it, it just hands the value off to anything that requests it. You can also \"bind\" providers, which is covered in the binds section of the docs.","title":"Intro"},{"location":"#di-pythonic-dependency-injection","text":"di is a modern dependency injection system, modeled around the simplicity of FastAPI's dependency injection. Key features: Intuitive : simple things are easy, complex things are possible. Succinct : declare what you want, and di figures out how to assmble it using type annotations. Correct : tested with MyPy: value: int = Depends(returns_str) gives an error. Flexible : with no fixed scopes, di can work within any framework, web or otherwise. Lifespans : di manages lifespans for dependencies by binding them to scopes. Caching : di caches values from dependencies to avoid duplicate computation. Scalability : di executes dependencies in parallel and only needs to solve them once. Performant : di moves sync dependencies into a threadpool to avoid blocking the event loop.","title":"di: pythonic dependency injection"},{"location":"#installation","text":"$ pip install di ---> 100% Warning This project is a work in progress. Until there is 1.X.Y release, expect breaking changes.","title":"Installation"},{"location":"#examples","text":"","title":"Examples"},{"location":"#simple-example","text":"Here is a simple example of how di works: from dataclasses import dataclass from di import Container , Dependant class A : ... class B : ... @dataclass class C : a : A b : B def main (): container = Container () c = container . execute_sync ( container . solve ( Dependant ( C ))) assert isinstance ( c , C ) assert isinstance ( c . a , A ) assert isinstance ( c . b , B )","title":"Simple Example"},{"location":"#why-do-i-need-dependency-injection-in-python-isnt-that-a-java-thing","text":"Dependency injection is a software architecture technique that helps us achieve inversion of control and dependency inversion (one of the five SOLID design principles). It is a common misconception that traditional software design principles do not apply to Python. As a matter of fact, you are probably using a lot of these techniques already! For example, the transport argument to httpx's Client ( docs ) is an excellent example of dependency injection. Most web frameworks employ inversion of control: when you define a view / controller, the web framework calls you! The same thing applies to CLIs (like click ) or TUIs (like Textual ). This is especially true for many newer webframeworks that not only use inversion of control but also dependency injection. Two great examples of this are FastAPI and BlackSheep . This project was born out of a desire to generalize and improve upon FastAPI's dependency injection system so that it can be used outside of FastAPI and even in other libraries. For a more comprehensive overview of Python projectes related to dependency injection, see Awesome Dependency Injection in Python .","title":"Why do I need dependency injection in Python? Isn't that a Java thing?"},{"location":"#project-aims","text":"This project aims to be a general dependency injection system, with a focus on providing the underlaying dependency injection functionality for other libaries. In other words, while you could use this as your a standalone dependency injection framework, you may find it to be a bit terse and verbose. There are also much more mature standalone dependency injection frameworks; I would recommend at least looking into python-dependency-injector since it is currently the most popular / widely used of the bunch.","title":"Project Aims"},{"location":"#in-depth-example","text":"With this background in place, let's dive into a more in-depth example. In this example, we'll look at what it would take for a web framework to provide dependecy injection to it's users via di . Let's start by looking at the User's code. from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) As a user, you have very little boilerplate. In fact, there is not a single line of code here that is not transmitting information. Now let's look at the web framework side of things. This part can get a bit complex, but it's okay because it's written once, in a library. First, we'll need to create a Container instance. This would be tied to the App or Router instance of the web framwork. from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) Next, we \"solve\" the users endpoint: from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) This should happen once, maybe at app startup. The framework can then store the solved object, which contains all of the information necessary to execute the dependency (dependency being in this case the user's endpoint/controller function). This is very important for performance: we want do the least amount of work possible for each incoming request. Finally, we execute the endpoint for each incoming request: from di import Container , Dependant # Framework code class Request : def __init__ ( self , value : int ) -> None : self . value = value async def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) res = await container . execute_async ( solved , values = { Request : Request ( 1 )}) assert res == 2 # User code class MyClass : def __init__ ( self , request : Request ) -> None : self . value = request . value def add ( self , value : int ) -> int : return self . value + value async def controller ( myobj : MyClass ) -> int : return myobj . add ( 1 ) When we do this, we provide the Request instance as a value. This means that di does not introspect at all into the Request to figure out how to build it, it just hands the value off to anything that requests it. You can also \"bind\" providers, which is covered in the binds section of the docs.","title":"In-depth example"},{"location":"architecture/","text":"Architecture The fundamental design principle of di is to split up the complexity of dependency injection into smaller component parts: Wiring: when we discover the dependencies. This includes doing reflection (inspecting signatures), looking for dependency markers, etc. Solving: when we build an execution plan, taking into account cached values, binds, etc. Execution: when we execute dependencies, possibly doing IO, parallelization, etc. We map these responsibilities to well defined classes/interfaces: Wiring: this is handled by Dependant Solving: this is handled by Container Execution: this is handled by Executor s There are also some ancilliary support classes: SolvedDependant holds the result of a call to Container.solve that can be passed to Container.execute_sync or Container.exeucte_async . Fundamentally, our class diagram looks like this: The mermaid diagram used to create this is below. classDiagram SolvedDependant \"1..n\" --o Dependant: aggregates into a DAG Container --> Dependant: calls get_dependencies() Container --> Executor: delegates execution Container --> SolvedDependant: stores solved DAG Container --> SolvedDependant: executes solved DAG class Dependant{ +get_dependencies() list~Dependant~ } class SolvedDependant{ +dag Mapping~Dependant, SetOfDependant~ } class Executor{ +execute(Callable]) } class Container{ +bind(Callable, Dependant) +enter_scope(Scope) Container +solve(Dependant) SolvedDependant +execute(SolvedDependant, Executor) Result }","title":"Architecture"},{"location":"architecture/#architecture","text":"The fundamental design principle of di is to split up the complexity of dependency injection into smaller component parts: Wiring: when we discover the dependencies. This includes doing reflection (inspecting signatures), looking for dependency markers, etc. Solving: when we build an execution plan, taking into account cached values, binds, etc. Execution: when we execute dependencies, possibly doing IO, parallelization, etc. We map these responsibilities to well defined classes/interfaces: Wiring: this is handled by Dependant Solving: this is handled by Container Execution: this is handled by Executor s There are also some ancilliary support classes: SolvedDependant holds the result of a call to Container.solve that can be passed to Container.execute_sync or Container.exeucte_async . Fundamentally, our class diagram looks like this: The mermaid diagram used to create this is below. classDiagram SolvedDependant \"1..n\" --o Dependant: aggregates into a DAG Container --> Dependant: calls get_dependencies() Container --> Executor: delegates execution Container --> SolvedDependant: stores solved DAG Container --> SolvedDependant: executes solved DAG class Dependant{ +get_dependencies() list~Dependant~ } class SolvedDependant{ +dag Mapping~Dependant, SetOfDependant~ } class Executor{ +execute(Callable]) } class Container{ +bind(Callable, Dependant) +enter_scope(Scope) Container +solve(Dependant) SolvedDependant +execute(SolvedDependant, Executor) Result }","title":"Architecture"},{"location":"binds/","text":"Binds Binds provide two important functions: A way to tell the container how to assemble things that can't be autowired, for example interfaces. A way to override dependencies in tests. Every bind in di consists of: A target callable: this can be a function, an interface / protocol or a concrete class A substitute dependency: an object implementing the DependantBase , usually just an instance of Dependant This means that binds are themselves dependencies: import sys from dataclasses import dataclass from typing import List if sys . version_info < ( 3 , 8 ): from typing_extensions import Protocol else : from typing import Protocol from di import Container , Dependant class DBProtocol ( Protocol ): async def execute ( self , sql : str ) -> None : ... async def controller ( db : DBProtocol ) -> None : await db . execute ( \"SELECT *\" ) @dataclass class DBConfig : host : str = \"localhost\" class Postgres ( DBProtocol ): def __init__ ( self , config : DBConfig ) -> None : self . host = config . host self . log : List [ str ] = [] async def execute ( self , sql : str ) -> None : self . log . append ( sql ) async def framework () -> None : container = Container () container . bind ( Dependant ( Postgres , scope = \"app\" ), DBProtocol ) # type: ignore solved = container . solve ( Dependant ( controller )) async with container . enter_scope ( \"app\" ): await container . execute_async ( solved ) db = await container . execute_async ( container . solve ( Dependant ( DBProtocol ))) assert isinstance ( db , Postgres ) assert db . log == [ \"SELECT *\" ] In this example we bind a concrete Postgres instance to DBProtocol , and we can see that di autowires Postgres as well! Binds can be used as a direct function call, in which case they are permanent, or as a context manager.","title":"Binds"},{"location":"binds/#binds","text":"Binds provide two important functions: A way to tell the container how to assemble things that can't be autowired, for example interfaces. A way to override dependencies in tests. Every bind in di consists of: A target callable: this can be a function, an interface / protocol or a concrete class A substitute dependency: an object implementing the DependantBase , usually just an instance of Dependant This means that binds are themselves dependencies: import sys from dataclasses import dataclass from typing import List if sys . version_info < ( 3 , 8 ): from typing_extensions import Protocol else : from typing import Protocol from di import Container , Dependant class DBProtocol ( Protocol ): async def execute ( self , sql : str ) -> None : ... async def controller ( db : DBProtocol ) -> None : await db . execute ( \"SELECT *\" ) @dataclass class DBConfig : host : str = \"localhost\" class Postgres ( DBProtocol ): def __init__ ( self , config : DBConfig ) -> None : self . host = config . host self . log : List [ str ] = [] async def execute ( self , sql : str ) -> None : self . log . append ( sql ) async def framework () -> None : container = Container () container . bind ( Dependant ( Postgres , scope = \"app\" ), DBProtocol ) # type: ignore solved = container . solve ( Dependant ( controller )) async with container . enter_scope ( \"app\" ): await container . execute_async ( solved ) db = await container . execute_async ( container . solve ( Dependant ( DBProtocol ))) assert isinstance ( db , Postgres ) assert db . log == [ \"SELECT *\" ] In this example we bind a concrete Postgres instance to DBProtocol , and we can see that di autowires Postgres as well! Binds can be used as a direct function call, in which case they are permanent, or as a context manager.","title":"Binds"},{"location":"contributing/","text":"Developer setup This is a pure Python project and should be straightforward to set up on Linux or MacOS. We do not support Windows for development, if you use Windows you'll have to use VSCode DevContainers or a similar solution. We use Poetry for dependency management, and most of the config is the pyproject.toml . Linting is done via git hooks, managed by pre-commit . The linters may change over time, but they are configured in our pre-commit-config.yaml . Most of the setup and interaction with these systems is encapsulated in our Makefile . Project setup First, fork the repo and then clone your fork: $ git clone https://github.com/adriangb/di.git ---> 100% $ cd di Now install the project dependencies. You will need Make installed along with a compatible Python version (currently, 3.9.X). To set up the project, simply run: $ make init This will create a .venv virtualenv that you can configure your IDE to use. Running tests $ make test Tests are run with pytest, so you can also run them manually or configure your IDE to run them. The tests are stored in the tests/ directory. Running linting Linting will run automatically on every commit. To disable this, you can commit with git commit --no-verify . You can also run linting manually: $ make lint Documentation The docs are written as markdown and built with MkDocs. Both the docs and their source code are stored in the docs/ directory. To preview the docs locally as you edit them, run $ make docs-serve All of the code fragments in the docs are stored as .py files in docs/src . These code fragments are tested as part of unit tests to ensure that the documentation stays up to date with the API. Releases This project uses continious integration and continious delivery on a trunk based workflow. Every merge into main should be fully functional code in a releasable state. As part of your pull request, you should propose what type of change is being made and determine the right version bump appropriately. While conventional commits are appreciated as a means of communication, especially for the merge commit, they are not required or enforced. You are however required to bump the package version in pyproject.toml . Every commit into main needs a version bump so that a release can be made, even if it is a refactor or \"chore\" type change. Once your change is merged, the new docs and PyPi package will be released automatically. Every time a release is made on PyPi, a corresponding GitHub release will be created to correlate PyPi versions to git commits.","title":"Contributing"},{"location":"contributing/#developer-setup","text":"This is a pure Python project and should be straightforward to set up on Linux or MacOS. We do not support Windows for development, if you use Windows you'll have to use VSCode DevContainers or a similar solution. We use Poetry for dependency management, and most of the config is the pyproject.toml . Linting is done via git hooks, managed by pre-commit . The linters may change over time, but they are configured in our pre-commit-config.yaml . Most of the setup and interaction with these systems is encapsulated in our Makefile .","title":"Developer setup"},{"location":"contributing/#project-setup","text":"First, fork the repo and then clone your fork: $ git clone https://github.com/adriangb/di.git ---> 100% $ cd di Now install the project dependencies. You will need Make installed along with a compatible Python version (currently, 3.9.X). To set up the project, simply run: $ make init This will create a .venv virtualenv that you can configure your IDE to use.","title":"Project setup"},{"location":"contributing/#running-tests","text":"$ make test Tests are run with pytest, so you can also run them manually or configure your IDE to run them. The tests are stored in the tests/ directory.","title":"Running tests"},{"location":"contributing/#running-linting","text":"Linting will run automatically on every commit. To disable this, you can commit with git commit --no-verify . You can also run linting manually: $ make lint","title":"Running linting"},{"location":"contributing/#documentation","text":"The docs are written as markdown and built with MkDocs. Both the docs and their source code are stored in the docs/ directory. To preview the docs locally as you edit them, run $ make docs-serve All of the code fragments in the docs are stored as .py files in docs/src . These code fragments are tested as part of unit tests to ensure that the documentation stays up to date with the API.","title":"Documentation"},{"location":"contributing/#releases","text":"This project uses continious integration and continious delivery on a trunk based workflow. Every merge into main should be fully functional code in a releasable state. As part of your pull request, you should propose what type of change is being made and determine the right version bump appropriately. While conventional commits are appreciated as a means of communication, especially for the merge commit, they are not required or enforced. You are however required to bump the package version in pyproject.toml . Every commit into main needs a version bump so that a release can be made, even if it is a refactor or \"chore\" type change. Once your change is merged, the new docs and PyPi package will be released automatically. Every time a release is made on PyPi, a corresponding GitHub release will be created to correlate PyPi versions to git commits.","title":"Releases"},{"location":"dependants/","text":"Dependants and the DependantBase Most of these docs use Depends and Dependency as the main markers and containers for dependencies. But the container doesn't actually know about either of these two things! In fact, the container only knows about the DependantBase , which you can find in di.api.dependencies . Dependency is just a concrete implementation of the DependantBase , and Depends is in turn a wrapper function around Dependency for the sole purpose of overriding the types that type checkers see. You can easily build your own version of Dependency and Depends , by inheriting from Dependency or by writing a DependantBase implementation from scratch. Note DependantBase is a relatively simple interface. We choose to use an ABC primarily so that it is inexpensive to do isinstance(something, DependantBase) , which comes up relatively often. Unlike ABCs, Protocols cannot be cheaply or accurately runtime checked in Python. Here is an example that extracts headers from requests: from __future__ import annotations import inspect from typing import Any , Mapping , Optional from di import Container , Dependant , Depends class Request : def __init__ ( self , headers : Mapping [ str , str ]) -> None : self . headers = { k . lower (): v for k , v in headers . items ()} class HeaderDependant ( Dependant [ Any ]): def __init__ ( self , alias : Optional [ str ]) -> None : self . alias = alias super () . __init__ ( call = None , scope = None , share = False ) def register_parameter ( self , param : inspect . Parameter ) -> HeaderDependant : if self . alias is not None : name = self . alias else : name = param . name . replace ( \"_\" , \"-\" ) def get_header ( request : Request = Depends ()) -> str : return param . annotation ( request . headers [ name ]) self . call = get_header # We could return a copy here to allow the same Dependant # to be used in multiple places like # dep = HeaderDependant(...) # def func1(abcd = dep): ... # def func2(efgh = dep): ... # In this scenario, `dep` would be modified in func2 to set # the header name to \"efgh\", which leads to incorrect results in func1 # The solution is to return a copy here instead of self, so that # the original instance is never modified in place return self def Header ( alias : Optional [ str ] = None ) -> Any : return HeaderDependant ( alias = alias ) # type: ignore async def web_framework () -> None : container = Container () valid_request = Request ( headers = { \"x-header-one\" : \"one\" , \"x-header-two\" : \"2\" }) with container . bind ( Dependant ( lambda : valid_request ), Request ): await container . execute_async ( container . solve ( Dependant ( controller ))) # success invalid_request = Request ( headers = { \"x-header-one\" : \"one\" }) with container . bind ( Dependant ( lambda : invalid_request ), Request ): try : await container . execute_async ( container . solve ( Dependant ( controller )) ) # fails except KeyError : pass else : raise AssertionError ( \"This call should have failed because x-header-two is missing\" ) def controller ( x_header_one : str = Header (), header_two_val : int = Header ( alias = \"x-header-two\" ) ) -> None : \"\"\"This is the only piece of user code\"\"\" assert x_header_one == \"one\" assert header_two_val == 2 Another good example of the customizability provided by DependantBase is the implementation of JointDependant , which lets you schedule and execute dependencies together even if they are not directly connected by wiring: from di import Container , Dependant from di.dependant import JoinedDependant class A : ... class B : executed = False def __init__ ( self ) -> None : B . executed = True def main (): container = Container () dependant = JoinedDependant ( Dependant ( A ), siblings = [ Dependant ( B )]) solved = container . solve ( dependant ) a = container . execute_sync ( solved ) assert isinstance ( a , A ) assert B . executed Here B is executed even though A does not depend on it. This is because JoinedDependant leverages the DependantBase interface to tell di that B is a dependency of A even if B is not a parameter or otherwise releated to A .","title":"Dependants"},{"location":"dependants/#dependants-and-the-dependantbase","text":"Most of these docs use Depends and Dependency as the main markers and containers for dependencies. But the container doesn't actually know about either of these two things! In fact, the container only knows about the DependantBase , which you can find in di.api.dependencies . Dependency is just a concrete implementation of the DependantBase , and Depends is in turn a wrapper function around Dependency for the sole purpose of overriding the types that type checkers see. You can easily build your own version of Dependency and Depends , by inheriting from Dependency or by writing a DependantBase implementation from scratch. Note DependantBase is a relatively simple interface. We choose to use an ABC primarily so that it is inexpensive to do isinstance(something, DependantBase) , which comes up relatively often. Unlike ABCs, Protocols cannot be cheaply or accurately runtime checked in Python. Here is an example that extracts headers from requests: from __future__ import annotations import inspect from typing import Any , Mapping , Optional from di import Container , Dependant , Depends class Request : def __init__ ( self , headers : Mapping [ str , str ]) -> None : self . headers = { k . lower (): v for k , v in headers . items ()} class HeaderDependant ( Dependant [ Any ]): def __init__ ( self , alias : Optional [ str ]) -> None : self . alias = alias super () . __init__ ( call = None , scope = None , share = False ) def register_parameter ( self , param : inspect . Parameter ) -> HeaderDependant : if self . alias is not None : name = self . alias else : name = param . name . replace ( \"_\" , \"-\" ) def get_header ( request : Request = Depends ()) -> str : return param . annotation ( request . headers [ name ]) self . call = get_header # We could return a copy here to allow the same Dependant # to be used in multiple places like # dep = HeaderDependant(...) # def func1(abcd = dep): ... # def func2(efgh = dep): ... # In this scenario, `dep` would be modified in func2 to set # the header name to \"efgh\", which leads to incorrect results in func1 # The solution is to return a copy here instead of self, so that # the original instance is never modified in place return self def Header ( alias : Optional [ str ] = None ) -> Any : return HeaderDependant ( alias = alias ) # type: ignore async def web_framework () -> None : container = Container () valid_request = Request ( headers = { \"x-header-one\" : \"one\" , \"x-header-two\" : \"2\" }) with container . bind ( Dependant ( lambda : valid_request ), Request ): await container . execute_async ( container . solve ( Dependant ( controller ))) # success invalid_request = Request ( headers = { \"x-header-one\" : \"one\" }) with container . bind ( Dependant ( lambda : invalid_request ), Request ): try : await container . execute_async ( container . solve ( Dependant ( controller )) ) # fails except KeyError : pass else : raise AssertionError ( \"This call should have failed because x-header-two is missing\" ) def controller ( x_header_one : str = Header (), header_two_val : int = Header ( alias = \"x-header-two\" ) ) -> None : \"\"\"This is the only piece of user code\"\"\" assert x_header_one == \"one\" assert header_two_val == 2 Another good example of the customizability provided by DependantBase is the implementation of JointDependant , which lets you schedule and execute dependencies together even if they are not directly connected by wiring: from di import Container , Dependant from di.dependant import JoinedDependant class A : ... class B : executed = False def __init__ ( self ) -> None : B . executed = True def main (): container = Container () dependant = JoinedDependant ( Dependant ( A ), siblings = [ Dependant ( B )]) solved = container . solve ( dependant ) a = container . execute_sync ( solved ) assert isinstance ( a , A ) assert B . executed Here B is executed even though A does not depend on it. This is because JoinedDependant leverages the DependantBase interface to tell di that B is a dependency of A even if B is not a parameter or otherwise releated to A .","title":"Dependants and the DependantBase"},{"location":"integrations/","text":"Integrations We do not provide any fully supported 3rd party integrations as of this moment. However, di is designed to easily be integrated into existing frameworks. Below are some samples that show how di might be used by web frameworks and other applications. These example are only for demonstration, and are missing critical features that would be required for a full fledged integration. The integrations will be shown from a users perspective, but you can see the source code for the framework side in docs/src/ . Textual Textual is a TUI (Text User Interface) framework for Python inspired by modern web development. In this example, we add dependency injection functionality into Textual and use it to inject an HTTP client that pulls a markdown file from the web and displays it in the console. This example mirrors Textual's own simple.py example . from dataclasses import dataclass from httpx import AsyncClient from rich.markdown import Markdown from textual.widgets import Footer , Header , ScrollView # type: ignore from di import Depends from docs.src.textual.src import App # type: ignore @dataclass class Config : url : str = \"https://raw.githubusercontent.com/willmcgugan/textual/main/examples/richreadme.md\" async def get_readme ( config : Config , client : AsyncClient = Depends ( scope = \"app\" ) ) -> Markdown : # URL could be loaded from config response = await client . get ( config . url ) response . raise_for_status () return Markdown ( response . text , hyperlinks = True ) class GridTest ( App ): async def on_load ( self ) -> None : \"\"\"Bind keys with the app loads (but before entering application mode)\"\"\" await self . bind ( \"b\" , \"view.toggle('sidebar')\" , \"Toggle sidebar\" ) await self . bind ( \"q\" , \"quit\" , \"Quit\" ) async def on_mount ( self , readme : Markdown = Depends ( get_readme )) -> None : \"\"\"Create and dock the widgets.\"\"\" # A scrollview to contain the markdown file body = ScrollView ( gutter = 1 ) # Header / footer / dock await self . view . dock ( Header (), edge = \"top\" ) await self . view . dock ( Footer (), edge = \"bottom\" ) # Dock the body in the remaining space await self . view . dock ( body , edge = \"right\" ) await self . call_later ( body . update , readme ) # type: ignore def main () -> None : GridTest . run ( title = \"Grid Test\" , log = \"textual.log\" ) # type: ignore Starlette Starlette is a microframework with async support. Adding dependency injection to Starlette is pretty straightforward. We just need to bind the incoming requests. from dataclasses import dataclass from starlette.requests import Request from starlette.responses import Response from starlette.testclient import TestClient from di import Depends from docs.src.starlette.src import App app = App () @dataclass class Config : host : str = \"localhost\" # could be loaded from env vars @dataclass class DBConnection : config : Config async def execute ( self , stmt : str ) -> None : print ( f \"Executing on { self . config . host } : { stmt } \" ) @app . get ( \"/test\" ) async def route ( request : Request , conn : DBConnection = Depends ( scope = \"app\" )): await conn . execute (( await request . body ()) . decode ()) return Response () def main () -> None : with TestClient ( app ) as client : res = client . get ( \"/test\" , data = b \"SELECT 1\" ) assert res . status_code == 200 A full implementation would also need ways to extract bodies, headers, etc. For an example of providing headers via dependency injection, see the Dependants docs .","title":"Integrations"},{"location":"integrations/#integrations","text":"We do not provide any fully supported 3rd party integrations as of this moment. However, di is designed to easily be integrated into existing frameworks. Below are some samples that show how di might be used by web frameworks and other applications. These example are only for demonstration, and are missing critical features that would be required for a full fledged integration. The integrations will be shown from a users perspective, but you can see the source code for the framework side in docs/src/ .","title":"Integrations"},{"location":"integrations/#textual","text":"Textual is a TUI (Text User Interface) framework for Python inspired by modern web development. In this example, we add dependency injection functionality into Textual and use it to inject an HTTP client that pulls a markdown file from the web and displays it in the console. This example mirrors Textual's own simple.py example . from dataclasses import dataclass from httpx import AsyncClient from rich.markdown import Markdown from textual.widgets import Footer , Header , ScrollView # type: ignore from di import Depends from docs.src.textual.src import App # type: ignore @dataclass class Config : url : str = \"https://raw.githubusercontent.com/willmcgugan/textual/main/examples/richreadme.md\" async def get_readme ( config : Config , client : AsyncClient = Depends ( scope = \"app\" ) ) -> Markdown : # URL could be loaded from config response = await client . get ( config . url ) response . raise_for_status () return Markdown ( response . text , hyperlinks = True ) class GridTest ( App ): async def on_load ( self ) -> None : \"\"\"Bind keys with the app loads (but before entering application mode)\"\"\" await self . bind ( \"b\" , \"view.toggle('sidebar')\" , \"Toggle sidebar\" ) await self . bind ( \"q\" , \"quit\" , \"Quit\" ) async def on_mount ( self , readme : Markdown = Depends ( get_readme )) -> None : \"\"\"Create and dock the widgets.\"\"\" # A scrollview to contain the markdown file body = ScrollView ( gutter = 1 ) # Header / footer / dock await self . view . dock ( Header (), edge = \"top\" ) await self . view . dock ( Footer (), edge = \"bottom\" ) # Dock the body in the remaining space await self . view . dock ( body , edge = \"right\" ) await self . call_later ( body . update , readme ) # type: ignore def main () -> None : GridTest . run ( title = \"Grid Test\" , log = \"textual.log\" ) # type: ignore","title":"Textual"},{"location":"integrations/#starlette","text":"Starlette is a microframework with async support. Adding dependency injection to Starlette is pretty straightforward. We just need to bind the incoming requests. from dataclasses import dataclass from starlette.requests import Request from starlette.responses import Response from starlette.testclient import TestClient from di import Depends from docs.src.starlette.src import App app = App () @dataclass class Config : host : str = \"localhost\" # could be loaded from env vars @dataclass class DBConnection : config : Config async def execute ( self , stmt : str ) -> None : print ( f \"Executing on { self . config . host } : { stmt } \" ) @app . get ( \"/test\" ) async def route ( request : Request , conn : DBConnection = Depends ( scope = \"app\" )): await conn . execute (( await request . body ()) . decode ()) return Response () def main () -> None : with TestClient ( app ) as client : res = client . get ( \"/test\" , data = b \"SELECT 1\" ) assert res . status_code == 200 A full implementation would also need ways to extract bodies, headers, etc. For an example of providing headers via dependency injection, see the Dependants docs .","title":"Starlette"},{"location":"scopes/","text":"Scopes Scopes are one of the fundamental concepts in dependency injection. Some dependency injection frameworks provide fixes scopes, for example: Singleton: only one instance is created Request: in web frameworks, this could be the lifetime of a request Prototype: re-initialized every time it is needed di generalizes this concept by putting control of scopes into the hands of the users / implementers: a scope in di is identified by any hashable value (a string, enum, int, etc.) and entering / exiting scopes is handled via context managers: async with container . enter_scope ( \"app\" ): async with container . enter_scope ( \"request\" ): async with container . enter_scope ( \"foo, bar, baz!\" ): Scopes provide a framework for several other important features: Dependency lifespans Dependency value sharing Every dependency is linked to a scope. When a scope exits, all dependencies linked to it are destroyed (if they have cleanup, the cleanup is run) and their value is no longer available as a share value. This means that dependencies scoped to an outer scope cannot depend on dependencies scoped to an inner scope: from di import Container , Dependant , Depends class Request : ... class DBConnection : def __init__ ( self , request : Request ) -> None : ... def controller ( conn : DBConnection = Depends ( scope = \"app\" )) -> None : ... def framework () -> None : container = Container () with container . enter_scope ( \"app\" ): with container . enter_scope ( \"request\" ): request = Request () with container . bind ( Dependant ( lambda : request , scope = \"request\" ), Request ): container . execute_sync ( container . solve ( Dependant ( controller ))) This example will fail with di.exceptions.ScopeViolationError because an \"app\" scoped dependency ( conn , as requested by controller via Depends(scope=\"app\") ) depends on a request scope dependency (in framework , we specify Dependant(..., scope=\"request\" ). This is because dependencies and scopes behave much a stack and references in general purpose langauges: you can't reference a function local once you exit that function. Even if we could hold onto the value once we exit the scope, that value could be a reference to an object that already had it's destructor run, for example a database connection that was closed.","title":"Scopes"},{"location":"scopes/#scopes","text":"Scopes are one of the fundamental concepts in dependency injection. Some dependency injection frameworks provide fixes scopes, for example: Singleton: only one instance is created Request: in web frameworks, this could be the lifetime of a request Prototype: re-initialized every time it is needed di generalizes this concept by putting control of scopes into the hands of the users / implementers: a scope in di is identified by any hashable value (a string, enum, int, etc.) and entering / exiting scopes is handled via context managers: async with container . enter_scope ( \"app\" ): async with container . enter_scope ( \"request\" ): async with container . enter_scope ( \"foo, bar, baz!\" ): Scopes provide a framework for several other important features: Dependency lifespans Dependency value sharing Every dependency is linked to a scope. When a scope exits, all dependencies linked to it are destroyed (if they have cleanup, the cleanup is run) and their value is no longer available as a share value. This means that dependencies scoped to an outer scope cannot depend on dependencies scoped to an inner scope: from di import Container , Dependant , Depends class Request : ... class DBConnection : def __init__ ( self , request : Request ) -> None : ... def controller ( conn : DBConnection = Depends ( scope = \"app\" )) -> None : ... def framework () -> None : container = Container () with container . enter_scope ( \"app\" ): with container . enter_scope ( \"request\" ): request = Request () with container . bind ( Dependant ( lambda : request , scope = \"request\" ), Request ): container . execute_sync ( container . solve ( Dependant ( controller ))) This example will fail with di.exceptions.ScopeViolationError because an \"app\" scoped dependency ( conn , as requested by controller via Depends(scope=\"app\") ) depends on a request scope dependency (in framework , we specify Dependant(..., scope=\"request\" ). This is because dependencies and scopes behave much a stack and references in general purpose langauges: you can't reference a function local once you exit that function. Even if we could hold onto the value once we exit the scope, that value could be a reference to an object that already had it's destructor run, for example a database connection that was closed.","title":"Scopes"},{"location":"sharing/","text":"Dependency sharing Often, you will have dependencies that share a sub dependency. For example, you probably only want to load your configuration from enviroment variables once and then re-use the same object in multiple dependencies. In di , we call this concept dependency sharing . How sharing works Dependencies are usually identfied by their callable provider (see dependants for ways in which you can change this). This could be the constructor for a type or an arbitrary callable encapsulated using Depends(...) . By default, dependencies are shared, but this behavior can be changed on a per-dependency basis using the share=False parameter. from random import random from di import Container , Dependant , Depends def controller ( v1 : object , # no marker is equivalent to Depends(object) v2 : object = Depends ( object ), # the default value is share=True v3 : float = Depends ( random , share = False ), # but you can set share=False ) -> None : assert v1 is v2 assert v1 is not v3 and v2 is not v3 def main () -> None : container = Container () container . execute_sync ( container . solve ( Dependant ( controller ))) Sharing and scopes Dependencies are share within their scope and any innner scopes. Once a dependency's scope exits, it's share value is discarded and the next time the scope is entered a fresh value will be computed.","title":"Sharing"},{"location":"sharing/#dependency-sharing","text":"Often, you will have dependencies that share a sub dependency. For example, you probably only want to load your configuration from enviroment variables once and then re-use the same object in multiple dependencies. In di , we call this concept dependency sharing .","title":"Dependency sharing"},{"location":"sharing/#how-sharing-works","text":"Dependencies are usually identfied by their callable provider (see dependants for ways in which you can change this). This could be the constructor for a type or an arbitrary callable encapsulated using Depends(...) . By default, dependencies are shared, but this behavior can be changed on a per-dependency basis using the share=False parameter. from random import random from di import Container , Dependant , Depends def controller ( v1 : object , # no marker is equivalent to Depends(object) v2 : object = Depends ( object ), # the default value is share=True v3 : float = Depends ( random , share = False ), # but you can set share=False ) -> None : assert v1 is v2 assert v1 is not v3 and v2 is not v3 def main () -> None : container = Container () container . execute_sync ( container . solve ( Dependant ( controller )))","title":"How sharing works"},{"location":"sharing/#sharing-and-scopes","text":"Dependencies are share within their scope and any innner scopes. Once a dependency's scope exits, it's share value is discarded and the next time the scope is entered a fresh value will be computed.","title":"Sharing and scopes"},{"location":"solving/","text":"Solving Solving a dependency means build a directed acyclic graph (DAG) of dependencies by inspecting sub dependencies and resolving binds. Once we solve a dependency, we can execute it without doing any introspection. Solving is done by the Container . The result of solving is stored in a SolvedDependant object which you can pass to Container.execute to get back the result. The simplest form of executing a dependency is thus: result = container . execute ( container . solve ( Dependant ( lambda : 1 ))) For a more comprehensive overview, see the architecture section. During solving, several things are checked: Any dependencies that can't be fully autowirired have binds. The same dependency is not used twice with different scopes. However, other things are not checked and are deffered to execution time. Namely, scopes are not validated during solving . This means that you can solve a DAG including \"request\" scoped depdendencies before entering the \"request\" scope. But it also means that any errors (like a missing scope) won't be caught until runtime. SolvedDependant di lets you pre-solve your dependencies so that you don't have to run the solver each time you execute. This usually comes with a huge performance boost, but only works if you have a static dependency graph. In practice, this just means that solving captures the current binds and won't be updated if there are changes to binds. Note that you can still have values in your DAG change, just not the shape of the DAG itself. For example, here is a more advanced use case where the framework solves the endpoint and then provides the Request as a value each time the endpoint is called. This means that di does not do any reflection for each request, nor does it have to do dependency resolution. Instead, only some basic checks on scopes are done and the dependencies are executed with almost no overhead. from di import Container , Dependant from di.api.solved import SolvedDependant # Framework code class Request : ... def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) assert isinstance ( solved , SolvedDependant ) container . execute_sync ( solved , values = { Request : Request ()}) dependencies = solved . get_flat_subdependants () assert all ( isinstance ( item , Dependant ) for item in dependencies ) assert set ( dependant . call for dependant in dependencies ) == { Request , MyClass } # User code class MyClass : ... def controller ( request : Request , myobj : MyClass ) -> None : ... Getting a list of dependencies di provides a convenience function to flatten the dependency DAG into a list off all sub dependencies in Container.get_flat_subdependants . from di import Container , Dependant from di.api.solved import SolvedDependant # Framework code class Request : ... def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) assert isinstance ( solved , SolvedDependant ) container . execute_sync ( solved , values = { Request : Request ()}) dependencies = solved . get_flat_subdependants () assert all ( isinstance ( item , Dependant ) for item in dependencies ) assert set ( dependant . call for dependant in dependencies ) == { Request , MyClass } # User code class MyClass : ... def controller ( request : Request , myobj : MyClass ) -> None : ... This lists all of the Dependants for the solved dependency. This means that you can create custom markers and easily enumerate them. For example, you might make a Header dependency and then want to know what headers are being requested by the controller, even if they are nested inside other dependencies: from di import Dependant class Header ( Dependant [ str ]): ... See the dependants section for a more complete example of this.","title":"Solving"},{"location":"solving/#solving","text":"Solving a dependency means build a directed acyclic graph (DAG) of dependencies by inspecting sub dependencies and resolving binds. Once we solve a dependency, we can execute it without doing any introspection. Solving is done by the Container . The result of solving is stored in a SolvedDependant object which you can pass to Container.execute to get back the result. The simplest form of executing a dependency is thus: result = container . execute ( container . solve ( Dependant ( lambda : 1 ))) For a more comprehensive overview, see the architecture section. During solving, several things are checked: Any dependencies that can't be fully autowirired have binds. The same dependency is not used twice with different scopes. However, other things are not checked and are deffered to execution time. Namely, scopes are not validated during solving . This means that you can solve a DAG including \"request\" scoped depdendencies before entering the \"request\" scope. But it also means that any errors (like a missing scope) won't be caught until runtime.","title":"Solving"},{"location":"solving/#solveddependant","text":"di lets you pre-solve your dependencies so that you don't have to run the solver each time you execute. This usually comes with a huge performance boost, but only works if you have a static dependency graph. In practice, this just means that solving captures the current binds and won't be updated if there are changes to binds. Note that you can still have values in your DAG change, just not the shape of the DAG itself. For example, here is a more advanced use case where the framework solves the endpoint and then provides the Request as a value each time the endpoint is called. This means that di does not do any reflection for each request, nor does it have to do dependency resolution. Instead, only some basic checks on scopes are done and the dependencies are executed with almost no overhead. from di import Container , Dependant from di.api.solved import SolvedDependant # Framework code class Request : ... def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) assert isinstance ( solved , SolvedDependant ) container . execute_sync ( solved , values = { Request : Request ()}) dependencies = solved . get_flat_subdependants () assert all ( isinstance ( item , Dependant ) for item in dependencies ) assert set ( dependant . call for dependant in dependencies ) == { Request , MyClass } # User code class MyClass : ... def controller ( request : Request , myobj : MyClass ) -> None : ...","title":"SolvedDependant"},{"location":"solving/#getting-a-list-of-dependencies","text":"di provides a convenience function to flatten the dependency DAG into a list off all sub dependencies in Container.get_flat_subdependants . from di import Container , Dependant from di.api.solved import SolvedDependant # Framework code class Request : ... def web_framework (): container = Container () solved = container . solve ( Dependant ( controller )) assert isinstance ( solved , SolvedDependant ) container . execute_sync ( solved , values = { Request : Request ()}) dependencies = solved . get_flat_subdependants () assert all ( isinstance ( item , Dependant ) for item in dependencies ) assert set ( dependant . call for dependant in dependencies ) == { Request , MyClass } # User code class MyClass : ... def controller ( request : Request , myobj : MyClass ) -> None : ... This lists all of the Dependants for the solved dependency. This means that you can create custom markers and easily enumerate them. For example, you might make a Header dependency and then want to know what headers are being requested by the controller, even if they are nested inside other dependencies: from di import Dependant class Header ( Dependant [ str ]): ... See the dependants section for a more complete example of this.","title":"Getting a list of dependencies"},{"location":"wiring/","text":"Wiring Wiring is the act of \"connecting\" together dependencies. There are generally two types of wiring that a DI container can do: Autowiring: where the container inspects the dependencies and automatically deduces their sub-dependencies. Manual wiring: where the user needs to register each sub-dependency with the container. Autowiring is generally preferrable: it reduces boilerplate and decouples your application from the Container's API. But autowiring is not always possible: sometimes the value is produced by a function ( value: int = some_function() ) or the type to inject is not the type in the annotation (when using interfaces / protocols). Autowiring in di Autowiring in di relies on inspecting function signatures and class constructors. The primary means of inspection are the standard library's inspect.signature and typing.get_type_hints . This makes autowiring compatible with a broad range of things, including: def functions Classes functools.partial binds Callable class classes or class instances (classes implementing __call__ ) Here is an example showing autowiring in action. Autowiring can work with dataclasses, even ones with a default_factory . In this example we'll load a config from the environment: import os from dataclasses import dataclass , field from di import Container , Dependant @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def controller ( conn : DBConn ) -> None : assert isinstance ( conn , DBConn ) async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) What makes this \"autowiring\" is that we didn't have to tell di how to construct DBConn : di detected that controller needed a DBConn and that DBConn in turn needs a Config instance. Manual wiring But what about situations where autowiring doesn't cut it? A common scenario for this is when type annotations are interfaces / protocols / ABCs, not concrete implementations. This is a good general practice and is very common in larger projects. It is also common for a dependency to come from a function, in which case we don't just want an instance of the type annotation, we want the value returned by a specific function. In these scenarios, some manual input from the user is required. There are two important concepts in di to handle this input: Binds: are used to swap out one dependency for another, which can be used to swap out an interface / protocol / ABC for a concrete implementation. Markers: usually Depends(...) which tell di how to construct the dependency (e.g. calling a function) as well as carrying other meteadata (like the scope, which you will see more about later on). Here is an example that makes use of both: import os import sys from dataclasses import dataclass , field if sys . version_info < ( 3 , 9 ): from typing_extensions import Annotated else : from typing import Annotated from di import Container , Dependant , Depends class AbstractDBConn : def execute ( self , query : str ) -> str : ... @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class ConcreteDBConn : def __init__ ( self , config : Config ) -> None : self . config = config def execute ( self , query : str ) -> str : return f \"executed { query } \" def get_user ( db : AbstractDBConn ) -> str : # this is a nonsensical query for demonstration purposes # you'd normally want to get the id from the request # and returna User object or something like that return db . execute ( \"SELECT name from Users LIMIT 1\" ) async def controller ( # markers can be added via Annotated user1 : Annotated [ str , Depends ( get_user )], # or as the default value, in which case types can be checked by MyPy/Pylance user2 : str = Depends ( get_user ), ) -> None : assert user1 == user2 == \"executed SELECT name from Users LIMIT 1\" async def framework (): container = Container () # note that di will also autowire the bind, in this case to inject Config container . bind ( Dependant ( ConcreteDBConn ), AbstractDBConn ) await container . execute_async ( container . solve ( Dependant ( controller ))) Binds in di are particularly powerful because the bound providers can themselves have dependencies, and those dependencies can even be autowired. For more information on binds in di , see our Binds docs. Markers can be set either as default values or via PEP 593 Annotated . There are advantages and disadvantages to each method: Annotated Pros of Annotated Compatible with other uses of default values, like dataclass' field or Pydantic's Field . Non-invasive modification of signatures: adding Depends(...) in Annotated should be ignored by anything except di . Functions/classes can be called as normal outside of di and the default values (when present) will be used. Cons of Annotated Types will not be checked: def func(v: Anotated[int, Depends(lambda: \"a\")]) does not produce an error in MyPy or Pylance. Annotated requires Python 3.9 (although it is available via the typing_extensions backport ) Using Annotated is more verbose, and can easily cause your function signature to spill into multiple lines. Default values Pros of default values Types will be checked: def func(v: int = Depends(lambda: \"a\")) produces an error in MyPy or Pylance. Function/class can no longer be called outside of di without passing values: you would get an instance of DependantBase as the default value. Cons of default values Incompatible with other uses of default values, like dataclass' field or Pydantic's Field . Having a default value in addition to Depends requires some customization of Dependant (to add a default: Any argument). Overall, use of Annotated is preferable to reduce coupling between di and your code, but using default values can make sense in some scenarios. Performance Reflection (inspecting function signatures for dependencies) is slow. For this reason, di tries to avoid it as much as possible. The best way to avoid extra introspection is to re-use Solved Dependants .","title":"Wiring"},{"location":"wiring/#wiring","text":"Wiring is the act of \"connecting\" together dependencies. There are generally two types of wiring that a DI container can do: Autowiring: where the container inspects the dependencies and automatically deduces their sub-dependencies. Manual wiring: where the user needs to register each sub-dependency with the container. Autowiring is generally preferrable: it reduces boilerplate and decouples your application from the Container's API. But autowiring is not always possible: sometimes the value is produced by a function ( value: int = some_function() ) or the type to inject is not the type in the annotation (when using interfaces / protocols).","title":"Wiring"},{"location":"wiring/#autowiring-in-di","text":"Autowiring in di relies on inspecting function signatures and class constructors. The primary means of inspection are the standard library's inspect.signature and typing.get_type_hints . This makes autowiring compatible with a broad range of things, including: def functions Classes functools.partial binds Callable class classes or class instances (classes implementing __call__ ) Here is an example showing autowiring in action. Autowiring can work with dataclasses, even ones with a default_factory . In this example we'll load a config from the environment: import os from dataclasses import dataclass , field from di import Container , Dependant @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def controller ( conn : DBConn ) -> None : assert isinstance ( conn , DBConn ) async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) What makes this \"autowiring\" is that we didn't have to tell di how to construct DBConn : di detected that controller needed a DBConn and that DBConn in turn needs a Config instance.","title":"Autowiring in di"},{"location":"wiring/#manual-wiring","text":"But what about situations where autowiring doesn't cut it? A common scenario for this is when type annotations are interfaces / protocols / ABCs, not concrete implementations. This is a good general practice and is very common in larger projects. It is also common for a dependency to come from a function, in which case we don't just want an instance of the type annotation, we want the value returned by a specific function. In these scenarios, some manual input from the user is required. There are two important concepts in di to handle this input: Binds: are used to swap out one dependency for another, which can be used to swap out an interface / protocol / ABC for a concrete implementation. Markers: usually Depends(...) which tell di how to construct the dependency (e.g. calling a function) as well as carrying other meteadata (like the scope, which you will see more about later on). Here is an example that makes use of both: import os import sys from dataclasses import dataclass , field if sys . version_info < ( 3 , 9 ): from typing_extensions import Annotated else : from typing import Annotated from di import Container , Dependant , Depends class AbstractDBConn : def execute ( self , query : str ) -> str : ... @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class ConcreteDBConn : def __init__ ( self , config : Config ) -> None : self . config = config def execute ( self , query : str ) -> str : return f \"executed { query } \" def get_user ( db : AbstractDBConn ) -> str : # this is a nonsensical query for demonstration purposes # you'd normally want to get the id from the request # and returna User object or something like that return db . execute ( \"SELECT name from Users LIMIT 1\" ) async def controller ( # markers can be added via Annotated user1 : Annotated [ str , Depends ( get_user )], # or as the default value, in which case types can be checked by MyPy/Pylance user2 : str = Depends ( get_user ), ) -> None : assert user1 == user2 == \"executed SELECT name from Users LIMIT 1\" async def framework (): container = Container () # note that di will also autowire the bind, in this case to inject Config container . bind ( Dependant ( ConcreteDBConn ), AbstractDBConn ) await container . execute_async ( container . solve ( Dependant ( controller ))) Binds in di are particularly powerful because the bound providers can themselves have dependencies, and those dependencies can even be autowired. For more information on binds in di , see our Binds docs. Markers can be set either as default values or via PEP 593 Annotated . There are advantages and disadvantages to each method:","title":"Manual wiring"},{"location":"wiring/#annotated","text":"","title":"Annotated"},{"location":"wiring/#pros-of-annotated","text":"Compatible with other uses of default values, like dataclass' field or Pydantic's Field . Non-invasive modification of signatures: adding Depends(...) in Annotated should be ignored by anything except di . Functions/classes can be called as normal outside of di and the default values (when present) will be used.","title":"Pros of Annotated"},{"location":"wiring/#cons-of-annotated","text":"Types will not be checked: def func(v: Anotated[int, Depends(lambda: \"a\")]) does not produce an error in MyPy or Pylance. Annotated requires Python 3.9 (although it is available via the typing_extensions backport ) Using Annotated is more verbose, and can easily cause your function signature to spill into multiple lines.","title":"Cons of Annotated"},{"location":"wiring/#default-values","text":"","title":"Default values"},{"location":"wiring/#pros-of-default-values","text":"Types will be checked: def func(v: int = Depends(lambda: \"a\")) produces an error in MyPy or Pylance. Function/class can no longer be called outside of di without passing values: you would get an instance of DependantBase as the default value.","title":"Pros of default values"},{"location":"wiring/#cons-of-default-values","text":"Incompatible with other uses of default values, like dataclass' field or Pydantic's Field . Having a default value in addition to Depends requires some customization of Dependant (to add a default: Any argument). Overall, use of Annotated is preferable to reduce coupling between di and your code, but using default values can make sense in some scenarios.","title":"Cons of default values"},{"location":"wiring/#performance","text":"Reflection (inspecting function signatures for dependencies) is slow. For this reason, di tries to avoid it as much as possible. The best way to avoid extra introspection is to re-use Solved Dependants .","title":"Performance"}]}