{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"di : pythonic dependency injection di is a modern dependency injection system, modeled around the simplicity of FastAPI's dependency injection. Key features: Intuitive : simple things are easy, complex things are possible. Succinct : declare what you want, and di figures out how to assmble it using type annotations. Correct : tested with MyPy: value: int = Depends(returns_str) gives an error. Flexible : with no fixed scopes, di can work within any framework, web or otherwise. Lifespans : di manages lifespans for dependencies by binding them to scopes. Caching : di caches values from dependencies to avoid duplicate computation. Scalability : di executes dependencies in parallel. Performant : di moves sync dependencies into a threadpool to avoid blocking the event loop. Installation $ pip install di ---> 100% Warning This project is a work in progress. Until there is 1.X.Y release, expect breaking changes. Examples Simple Example Here is a simple example of how di works: from dataclasses import dataclass from di import Container , Dependant class A : ... class B : ... @dataclass class C : a : A b : B def main (): container = Container () c = container . execute_sync ( container . solve ( Dependant ( C ))) assert isinstance ( c , C ) assert isinstance ( c . a , A ) assert isinstance ( c . b , B ) In-depth example In this example, we'll look at what it would take for a web framework to provide dependecy injection to it's users via di . First we declare a dependency. We'll call it Request like if it were an incoming HTTP request. This is something the web framework would provide and manage. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Next, we'll declare a controller / endpoint that uses the request. This is the only code the user would have to write. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Now we'll define what the web framework needs to do to glue everything together. This part can get a bit complex, but it's okay because it's written once, in a library. Users don't need to interact with the container or entering/exiting scopes (although they can if they want to). We start by creating a container. This would happen when the app / framework in initialized. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Next, we enter a \"request\" scope. This would happen for each incoming request. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Note that \"request\" does not have any special meaning to di : any hashable value (strings, enums, integers, etc.) will do. Frameworks using di need to establish semantic meanings for their scopes and communicate them with their users, but no changes in di are necessary to add more socpes. Next can bind our request instance: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Tip We didn't have to be in the \"request\" scope to do the bind, the opposite order (bind then enter scope) works just as well. Binds are always a callable. They can even have their own dependencies (e.g. container.bind(Dependant(callable_with_dependencies)) ) and declare their own scope (see next paragraph). But in this case we want to use the same Request instance everywhere, so we define a lambda that always returns the same instance. Although not strictly necessary in this case ( Request is not a context maanger), we pass scope=\"request\" to Dependant to signify that we want teardown for that dependncy to happen when we exit the \"request\" scope. If Request was a context manager like dependency (a dependency with yield ), then it's teardown (the section after yield ) would we run when we exit the \"request\" scope. Finally, we execute the user's controller / endpoint: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 When we called execute() , di checked controller and saw that it needed a Request . Then it looked at the binds, found the bound provider and injected that. Project Aims This project is primarily geared for enviroments that already use inversion of control (think web frameworks, CLI frameworks or anything else where you define functions and \"it calls you\"). It particularly excels in async / concurrent environments, since the DI system has first class support for async dependencies and can gather dependencies concurrently.","title":"Intro"},{"location":"#di-pythonic-dependency-injection","text":"di is a modern dependency injection system, modeled around the simplicity of FastAPI's dependency injection. Key features: Intuitive : simple things are easy, complex things are possible. Succinct : declare what you want, and di figures out how to assmble it using type annotations. Correct : tested with MyPy: value: int = Depends(returns_str) gives an error. Flexible : with no fixed scopes, di can work within any framework, web or otherwise. Lifespans : di manages lifespans for dependencies by binding them to scopes. Caching : di caches values from dependencies to avoid duplicate computation. Scalability : di executes dependencies in parallel. Performant : di moves sync dependencies into a threadpool to avoid blocking the event loop.","title":"di: pythonic dependency injection"},{"location":"#installation","text":"$ pip install di ---> 100% Warning This project is a work in progress. Until there is 1.X.Y release, expect breaking changes.","title":"Installation"},{"location":"#examples","text":"","title":"Examples"},{"location":"#simple-example","text":"Here is a simple example of how di works: from dataclasses import dataclass from di import Container , Dependant class A : ... class B : ... @dataclass class C : a : A b : B def main (): container = Container () c = container . execute_sync ( container . solve ( Dependant ( C ))) assert isinstance ( c , C ) assert isinstance ( c . a , A ) assert isinstance ( c . b , B )","title":"Simple Example"},{"location":"#in-depth-example","text":"In this example, we'll look at what it would take for a web framework to provide dependecy injection to it's users via di . First we declare a dependency. We'll call it Request like if it were an incoming HTTP request. This is something the web framework would provide and manage. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Next, we'll declare a controller / endpoint that uses the request. This is the only code the user would have to write. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Now we'll define what the web framework needs to do to glue everything together. This part can get a bit complex, but it's okay because it's written once, in a library. Users don't need to interact with the container or entering/exiting scopes (although they can if they want to). We start by creating a container. This would happen when the app / framework in initialized. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Next, we enter a \"request\" scope. This would happen for each incoming request. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Note that \"request\" does not have any special meaning to di : any hashable value (strings, enums, integers, etc.) will do. Frameworks using di need to establish semantic meanings for their scopes and communicate them with their users, but no changes in di are necessary to add more socpes. Next can bind our request instance: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 Tip We didn't have to be in the \"request\" scope to do the bind, the opposite order (bind then enter scope) works just as well. Binds are always a callable. They can even have their own dependencies (e.g. container.bind(Dependant(callable_with_dependencies)) ) and declare their own scope (see next paragraph). But in this case we want to use the same Request instance everywhere, so we define a lambda that always returns the same instance. Although not strictly necessary in this case ( Request is not a context maanger), we pass scope=\"request\" to Dependant to signify that we want teardown for that dependncy to happen when we exit the \"request\" scope. If Request was a context manager like dependency (a dependency with yield ), then it's teardown (the section after yield ) would we run when we exit the \"request\" scope. Finally, we execute the user's controller / endpoint: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request ) with container . bind ( request_provider , Request ): res = await container . execute_async ( container . solve ( Dependant ( controller ))) assert res == 2 When we called execute() , di checked controller and saw that it needed a Request . Then it looked at the binds, found the bound provider and injected that.","title":"In-depth example"},{"location":"#project-aims","text":"This project is primarily geared for enviroments that already use inversion of control (think web frameworks, CLI frameworks or anything else where you define functions and \"it calls you\"). It particularly excels in async / concurrent environments, since the DI system has first class support for async dependencies and can gather dependencies concurrently.","title":"Project Aims"},{"location":"binds/","text":"Binds Binds provide two important functions: A way to tell the container how to assemble things that can't be autowired, for example interfaces. A way to override dependencies in tests. Every bind in di consists of: A target callable: this can be a function, an interface / protocol or a concrete class A substitute dependency: an object implementing the DependencyProtocol , usually just an instance of Dependant This means that binds are themselves dependencies: from dataclasses import dataclass from typing import List , Protocol from di import Container , Dependant class DBProtocol ( Protocol ): async def execute ( self , sql : str ) -> None : ... async def controller ( db : DBProtocol ) -> None : await db . execute ( \"SELECT *\" ) @dataclass class DBConfig : host : str = \"localhost\" class Postgres ( DBProtocol ): def __init__ ( self , config : DBConfig ) -> None : self . host = config . host self . log : List [ str ] = [] async def execute ( self , sql : str ) -> None : self . log . append ( sql ) async def framework () -> None : container = Container () container . bind ( Dependant ( Postgres , scope = \"app\" ), DBProtocol ) # type: ignore solved = container . solve ( Dependant ( controller )) async with container . enter_local_scope ( \"app\" ): # type: ignore await container . execute_async ( solved ) db = await container . execute_async ( container . solve ( Dependant ( DBProtocol ))) assert isinstance ( db , Postgres ) assert db . log == [ \"SELECT *\" ] In this example we bind a concrete Postgres instance to DBProtocol , and we can see that di autowires Postgres as well! Binds can be used as a direct function call, in which case they are permanent, or as a context manager.","title":"Binds"},{"location":"binds/#binds","text":"Binds provide two important functions: A way to tell the container how to assemble things that can't be autowired, for example interfaces. A way to override dependencies in tests. Every bind in di consists of: A target callable: this can be a function, an interface / protocol or a concrete class A substitute dependency: an object implementing the DependencyProtocol , usually just an instance of Dependant This means that binds are themselves dependencies: from dataclasses import dataclass from typing import List , Protocol from di import Container , Dependant class DBProtocol ( Protocol ): async def execute ( self , sql : str ) -> None : ... async def controller ( db : DBProtocol ) -> None : await db . execute ( \"SELECT *\" ) @dataclass class DBConfig : host : str = \"localhost\" class Postgres ( DBProtocol ): def __init__ ( self , config : DBConfig ) -> None : self . host = config . host self . log : List [ str ] = [] async def execute ( self , sql : str ) -> None : self . log . append ( sql ) async def framework () -> None : container = Container () container . bind ( Dependant ( Postgres , scope = \"app\" ), DBProtocol ) # type: ignore solved = container . solve ( Dependant ( controller )) async with container . enter_local_scope ( \"app\" ): # type: ignore await container . execute_async ( solved ) db = await container . execute_async ( container . solve ( Dependant ( DBProtocol ))) assert isinstance ( db , Postgres ) assert db . log == [ \"SELECT *\" ] In this example we bind a concrete Postgres instance to DBProtocol , and we can see that di autowires Postgres as well! Binds can be used as a direct function call, in which case they are permanent, or as a context manager.","title":"Binds"},{"location":"contributing/","text":"Developer setup This is a pure Python project and should be straightforward to set up on Linux or MacOS. We do not support Windows for development, if you use Windows you'll have to use VSCode DevContainers or a similar solution. We use Poetry for dependency management, and most of the config is the pyproject.toml . Linting is done via git hooks, managed by pre-commit . The linters may change over time, but they are configured in our pre-commit-config.yaml . Most of the setup and interaction with these systems is encapsulated in our Makefile . Project setup First, fork the repo and then clone your fork: $ git clone https://github.com/adriangb/di.git ---> 100% $ cd di Now install the project dependencies. You will need Make installed along with a compatible Python version (currently, 3.9.X). To set up the project, simply run: $ make init This will create a .venv virtualenv that you can configure your IDE to use. Running tests $ make test Tests are run with pytest, so you can also run them manually or configure your IDE to run them. The tests are stored in the tests/ directory. Running linting Linting will run automatically on every commit. To disable this, you can commit with git commit --no-verify . You can also run linting manually: $ make lint Documentation The docs are written as markdown and built with MkDocs. Both the docs and their source code are stored in the docs/ directory. To preview the docs locally as you edit them, run $ make docs-serve All of the code fragments in the docs are stored as .py files in docs/src . These code fragments are tested as part of unit tests to ensure that the documentation stays up to date with the API. Releases This project uses continious integration and continious delivery (CI/CD) and a trunk based workflow. We do not want any long lived feature branches (although we won't stop you from making them in your fork), and every merge into main should be fully functional code in a releasable state. Because we intend to release every merge into main automatically, pull requests will check that you bump the project version. The project version is stored in our pyproject.toml and uses semantic versioning. As part of your pull request, you should propose what type of change is being made and determine the right version bump appropriately. Once your change is merged, the new docs and PyPi package will be released automatically. Every time a release is made on PyPi, a corresponding GitHub release will be created to allow correlating PyPi versions to VCS versions.","title":"Contributing"},{"location":"contributing/#developer-setup","text":"This is a pure Python project and should be straightforward to set up on Linux or MacOS. We do not support Windows for development, if you use Windows you'll have to use VSCode DevContainers or a similar solution. We use Poetry for dependency management, and most of the config is the pyproject.toml . Linting is done via git hooks, managed by pre-commit . The linters may change over time, but they are configured in our pre-commit-config.yaml . Most of the setup and interaction with these systems is encapsulated in our Makefile .","title":"Developer setup"},{"location":"contributing/#project-setup","text":"First, fork the repo and then clone your fork: $ git clone https://github.com/adriangb/di.git ---> 100% $ cd di Now install the project dependencies. You will need Make installed along with a compatible Python version (currently, 3.9.X). To set up the project, simply run: $ make init This will create a .venv virtualenv that you can configure your IDE to use.","title":"Project setup"},{"location":"contributing/#running-tests","text":"$ make test Tests are run with pytest, so you can also run them manually or configure your IDE to run them. The tests are stored in the tests/ directory.","title":"Running tests"},{"location":"contributing/#running-linting","text":"Linting will run automatically on every commit. To disable this, you can commit with git commit --no-verify . You can also run linting manually: $ make lint","title":"Running linting"},{"location":"contributing/#documentation","text":"The docs are written as markdown and built with MkDocs. Both the docs and their source code are stored in the docs/ directory. To preview the docs locally as you edit them, run $ make docs-serve All of the code fragments in the docs are stored as .py files in docs/src . These code fragments are tested as part of unit tests to ensure that the documentation stays up to date with the API.","title":"Documentation"},{"location":"contributing/#releases","text":"This project uses continious integration and continious delivery (CI/CD) and a trunk based workflow. We do not want any long lived feature branches (although we won't stop you from making them in your fork), and every merge into main should be fully functional code in a releasable state. Because we intend to release every merge into main automatically, pull requests will check that you bump the project version. The project version is stored in our pyproject.toml and uses semantic versioning. As part of your pull request, you should propose what type of change is being made and determine the right version bump appropriately. Once your change is merged, the new docs and PyPi package will be released automatically. Every time a release is made on PyPi, a corresponding GitHub release will be created to allow correlating PyPi versions to VCS versions.","title":"Releases"},{"location":"dependants/","text":"Dependants and the DependantProtocol Most of these docs use Depends and Dependency as the main markers and containers for dependencies. But the container doesn't actually know about either of these two things! In fact, the container only knows about the DependantProtocol , which you can find in di.dependency . Dependency is just a concrete implementation of the DependantProtocol , and Depends is in turn a wrapper function around Dependency for the sole purpose of overriding the types that type checkers see. You can easily build your own version of Dependency and Depends , either by inheriting from Dependency or by writing a DependantProtocol implementation from scratch. There are many use cases for this, including: Carrying extra data in the marker by making a class that accepts extra arguments in __init__ . Providing a callable implementation that depends on user defined parameters. Hiding options like scope or share from users where it does not make sense to change them. An example of creating Security dependencies for a web framework is available in the the Security docs . Here is another example that extracts headers from requests: import inspect from typing import Any , Callable , Mapping , Optional from di import Container , Dependant , Depends class Request : def __init__ ( self , headers : Mapping [ str , str ]) -> None : self . headers = { k . lower (): v for k , v in headers . items ()} class HeaderDependant ( Dependant [ Any ]): def __init__ ( self , alias : Optional [ str ]) -> None : self . alias = alias super () . __init__ ( call = None , scope = None , share = False ) def infer_call_from_annotation ( self , param : inspect . Parameter ) -> Callable [[ Request ], Any ]: if self . alias is not None : name = self . alias else : name = param . name . replace ( \"_\" , \"-\" ) def get_header ( request : Request = Depends ()) -> str : return param . annotation ( request . headers [ name ]) return get_header def Header ( alias : Optional [ str ] = None ) -> Any : return HeaderDependant ( alias = alias ) # type: ignore async def web_framework () -> None : container = Container () valid_request = Request ( headers = { \"x-header-one\" : \"one\" , \"x-header-two\" : \"2\" }) with container . bind ( Dependant ( lambda : valid_request ), Request ): await container . execute_async ( container . solve ( Dependant ( controller ))) # success invalid_request = Request ( headers = { \"x-header-one\" : \"one\" }) with container . bind ( Dependant ( lambda : invalid_request ), Request ): try : await container . execute_async ( container . solve ( Dependant ( controller )) ) # fails except KeyError : pass else : raise AssertionError ( \"This call should have failed because x-header-two is missing\" ) def controller ( x_header_one : str = Header (), header_two_val : int = Header ( alias = \"x-header-two\" ) ) -> None : \"\"\"This is the only piece of user code\"\"\" assert x_header_one == \"one\" assert header_two_val == 2","title":"Dependants"},{"location":"dependants/#dependants-and-the-dependantprotocol","text":"Most of these docs use Depends and Dependency as the main markers and containers for dependencies. But the container doesn't actually know about either of these two things! In fact, the container only knows about the DependantProtocol , which you can find in di.dependency . Dependency is just a concrete implementation of the DependantProtocol , and Depends is in turn a wrapper function around Dependency for the sole purpose of overriding the types that type checkers see. You can easily build your own version of Dependency and Depends , either by inheriting from Dependency or by writing a DependantProtocol implementation from scratch. There are many use cases for this, including: Carrying extra data in the marker by making a class that accepts extra arguments in __init__ . Providing a callable implementation that depends on user defined parameters. Hiding options like scope or share from users where it does not make sense to change them. An example of creating Security dependencies for a web framework is available in the the Security docs . Here is another example that extracts headers from requests: import inspect from typing import Any , Callable , Mapping , Optional from di import Container , Dependant , Depends class Request : def __init__ ( self , headers : Mapping [ str , str ]) -> None : self . headers = { k . lower (): v for k , v in headers . items ()} class HeaderDependant ( Dependant [ Any ]): def __init__ ( self , alias : Optional [ str ]) -> None : self . alias = alias super () . __init__ ( call = None , scope = None , share = False ) def infer_call_from_annotation ( self , param : inspect . Parameter ) -> Callable [[ Request ], Any ]: if self . alias is not None : name = self . alias else : name = param . name . replace ( \"_\" , \"-\" ) def get_header ( request : Request = Depends ()) -> str : return param . annotation ( request . headers [ name ]) return get_header def Header ( alias : Optional [ str ] = None ) -> Any : return HeaderDependant ( alias = alias ) # type: ignore async def web_framework () -> None : container = Container () valid_request = Request ( headers = { \"x-header-one\" : \"one\" , \"x-header-two\" : \"2\" }) with container . bind ( Dependant ( lambda : valid_request ), Request ): await container . execute_async ( container . solve ( Dependant ( controller ))) # success invalid_request = Request ( headers = { \"x-header-one\" : \"one\" }) with container . bind ( Dependant ( lambda : invalid_request ), Request ): try : await container . execute_async ( container . solve ( Dependant ( controller )) ) # fails except KeyError : pass else : raise AssertionError ( \"This call should have failed because x-header-two is missing\" ) def controller ( x_header_one : str = Header (), header_two_val : int = Header ( alias = \"x-header-two\" ) ) -> None : \"\"\"This is the only piece of user code\"\"\" assert x_header_one == \"one\" assert header_two_val == 2","title":"Dependants and the DependantProtocol"},{"location":"integrations/","text":"Integrations We do not provide any fully supported 3rd party integrations as of this moment. However, di is designed to easily be integrated into existing frameworks. Below are some samples that show how di might be used by web frameworks and other applications. These example are only for demonstration, and are missing critical features that would be required for a full fledged integration. The integrations will be shown from a users perspective, but you can see the source code for the framework side in docs/src/ . Textual Textual is a TUI (Text User Interface) framework for Python inspired by modern web development. In this example, we add dependency injection functionality into Textual and use it to inject an HTTP client that pulls a markdown file from the web and displays it in the console. This example mirrors Textual's own simple.py example . from dataclasses import dataclass from httpx import AsyncClient from rich.markdown import Markdown from textual.widgets import Footer , Header , ScrollView # type: ignore from di import Depends from docs.src.textual.src import App # type: ignore @dataclass class Config : url : str = \"https://raw.githubusercontent.com/willmcgugan/textual/main/examples/richreadme.md\" async def get_readme ( config : Config , client : AsyncClient = Depends ( scope = \"app\" ) ) -> Markdown : # URL could be loaded from config response = await client . get ( config . url ) response . raise_for_status () return Markdown ( response . text , hyperlinks = True ) class GridTest ( App ): async def on_load ( self ) -> None : \"\"\"Bind keys with the app loads (but before entering application mode)\"\"\" await self . bind ( \"b\" , \"view.toggle('sidebar')\" , \"Toggle sidebar\" ) await self . bind ( \"q\" , \"quit\" , \"Quit\" ) async def on_mount ( self , readme : Markdown = Depends ( get_readme )) -> None : \"\"\"Create and dock the widgets.\"\"\" # A scrollview to contain the markdown file body = ScrollView ( gutter = 1 ) # Header / footer / dock await self . view . dock ( Header (), edge = \"top\" ) await self . view . dock ( Footer (), edge = \"bottom\" ) # Dock the body in the remaining space await self . view . dock ( body , edge = \"right\" ) await self . call_later ( body . update , readme ) # type: ignore def main () -> None : GridTest . run ( title = \"Grid Test\" , log = \"textual.log\" ) # type: ignore Starlette Starlette is a microframework with async support. Adding dependency injection to Starlette is pretty straightforward. We just need to bind the incoming requests. from dataclasses import dataclass from starlette.requests import Request from starlette.responses import Response from starlette.testclient import TestClient from di import Depends from docs.src.starlette.src import App app = App () @dataclass class Config : host : str = \"localhost\" # could be loaded from env vars @dataclass class DBConnection : config : Config async def execute ( self , stmt : str ) -> None : print ( f \"Executing on { self . config . host } : { stmt } \" ) @app . get ( \"/test\" ) async def route ( request : Request , conn : DBConnection = Depends ( scope = \"app\" )): await conn . execute (( await request . body ()) . decode ()) return Response () def main () -> None : with TestClient ( app ) as client : res = client . get ( \"/test\" , data = b \"SELECT 1\" ) assert res . status_code == 200 A full implementation would also need ways to extract bodies, headers, etc. For an example of providing headers via dependency injection, see the Dependants docs .","title":"Integrations"},{"location":"integrations/#integrations","text":"We do not provide any fully supported 3rd party integrations as of this moment. However, di is designed to easily be integrated into existing frameworks. Below are some samples that show how di might be used by web frameworks and other applications. These example are only for demonstration, and are missing critical features that would be required for a full fledged integration. The integrations will be shown from a users perspective, but you can see the source code for the framework side in docs/src/ .","title":"Integrations"},{"location":"integrations/#textual","text":"Textual is a TUI (Text User Interface) framework for Python inspired by modern web development. In this example, we add dependency injection functionality into Textual and use it to inject an HTTP client that pulls a markdown file from the web and displays it in the console. This example mirrors Textual's own simple.py example . from dataclasses import dataclass from httpx import AsyncClient from rich.markdown import Markdown from textual.widgets import Footer , Header , ScrollView # type: ignore from di import Depends from docs.src.textual.src import App # type: ignore @dataclass class Config : url : str = \"https://raw.githubusercontent.com/willmcgugan/textual/main/examples/richreadme.md\" async def get_readme ( config : Config , client : AsyncClient = Depends ( scope = \"app\" ) ) -> Markdown : # URL could be loaded from config response = await client . get ( config . url ) response . raise_for_status () return Markdown ( response . text , hyperlinks = True ) class GridTest ( App ): async def on_load ( self ) -> None : \"\"\"Bind keys with the app loads (but before entering application mode)\"\"\" await self . bind ( \"b\" , \"view.toggle('sidebar')\" , \"Toggle sidebar\" ) await self . bind ( \"q\" , \"quit\" , \"Quit\" ) async def on_mount ( self , readme : Markdown = Depends ( get_readme )) -> None : \"\"\"Create and dock the widgets.\"\"\" # A scrollview to contain the markdown file body = ScrollView ( gutter = 1 ) # Header / footer / dock await self . view . dock ( Header (), edge = \"top\" ) await self . view . dock ( Footer (), edge = \"bottom\" ) # Dock the body in the remaining space await self . view . dock ( body , edge = \"right\" ) await self . call_later ( body . update , readme ) # type: ignore def main () -> None : GridTest . run ( title = \"Grid Test\" , log = \"textual.log\" ) # type: ignore","title":"Textual"},{"location":"integrations/#starlette","text":"Starlette is a microframework with async support. Adding dependency injection to Starlette is pretty straightforward. We just need to bind the incoming requests. from dataclasses import dataclass from starlette.requests import Request from starlette.responses import Response from starlette.testclient import TestClient from di import Depends from docs.src.starlette.src import App app = App () @dataclass class Config : host : str = \"localhost\" # could be loaded from env vars @dataclass class DBConnection : config : Config async def execute ( self , stmt : str ) -> None : print ( f \"Executing on { self . config . host } : { stmt } \" ) @app . get ( \"/test\" ) async def route ( request : Request , conn : DBConnection = Depends ( scope = \"app\" )): await conn . execute (( await request . body ()) . decode ()) return Response () def main () -> None : with TestClient ( app ) as client : res = client . get ( \"/test\" , data = b \"SELECT 1\" ) assert res . status_code == 200 A full implementation would also need ways to extract bodies, headers, etc. For an example of providing headers via dependency injection, see the Dependants docs .","title":"Starlette"},{"location":"scopes/","text":"Scopes Scopes are one of the fundamental concepts in dependency injection. Some dependency injection frameworks provide fixes scopes, for example: Singleton: only one instance is created Request: in web frameworks, this could be the lifetime of a request Prototype: re-initialized every time it is needed di generalizes this concept by putting control of scopes into the hands of the users / implementers: a scope in di is identified by any hashable value (a string, enum, int, etc.) and entering / exiting scopes is handled via context managers: async with container . enter_global_scope ( \"app\" ): async with container . enter_local_scope ( 123 ): ... Scopes provide a framework for several other important features: Dependency lifespans Dependency value sharing Every dependency is linked to a scope. When a scope exits, all dependencies linked to it are destroyed (if they have cleanup, the cleanup is run) and their value is no longer available as a share value. This means that dependencies scoped to an outer scope cannot depend on dependencies scoped to an inner scope: from di import Container , Dependant , Depends class Request : ... class DBConnection : def __init__ ( self , request : Request ) -> None : ... def controller ( conn : DBConnection = Depends ( scope = \"app\" )) -> None : ... def framework () -> None : container = Container () with container . enter_global_scope ( \"app\" ): with container . enter_local_scope ( \"request\" ): request = Request () with container . bind ( Dependant ( lambda : request , scope = \"request\" ), Request ): container . execute_sync ( container . solve ( Dependant ( controller ))) This example will fail with di.exceptions.ScopeViolationError because an \"app\" scoped dependency ( conn , as requested by controller via Depends(scope=\"app\") ) depends on a request scope dependency (in framework , we specify Dependant(..., scope=\"request\" ). This is because dependencies and scopes behave much a stack and references in general purpose langauges: you can't reference a function local once you exit that function. Even if we could hold onto the value once we exit the scope, that value could be a reference to an object that already had it's destructor run, for example a database connection that was closed. Local vs. global scopes There are two types of scopes in di : Local: localized to the current thread/coroutine via contextvars . Global: applied to the Container object itself, and hence share by any threads or coroutines that share the same Container object. You can enter a local scope via Container.enter_local_scope and a global one via Container.enter_global_scope . This can be useful to share a database connection between requests (global scope) but have each request have it's own local state (local scope), even if multiple requests are handled concurrently.","title":"Scopes"},{"location":"scopes/#scopes","text":"Scopes are one of the fundamental concepts in dependency injection. Some dependency injection frameworks provide fixes scopes, for example: Singleton: only one instance is created Request: in web frameworks, this could be the lifetime of a request Prototype: re-initialized every time it is needed di generalizes this concept by putting control of scopes into the hands of the users / implementers: a scope in di is identified by any hashable value (a string, enum, int, etc.) and entering / exiting scopes is handled via context managers: async with container . enter_global_scope ( \"app\" ): async with container . enter_local_scope ( 123 ): ... Scopes provide a framework for several other important features: Dependency lifespans Dependency value sharing Every dependency is linked to a scope. When a scope exits, all dependencies linked to it are destroyed (if they have cleanup, the cleanup is run) and their value is no longer available as a share value. This means that dependencies scoped to an outer scope cannot depend on dependencies scoped to an inner scope: from di import Container , Dependant , Depends class Request : ... class DBConnection : def __init__ ( self , request : Request ) -> None : ... def controller ( conn : DBConnection = Depends ( scope = \"app\" )) -> None : ... def framework () -> None : container = Container () with container . enter_global_scope ( \"app\" ): with container . enter_local_scope ( \"request\" ): request = Request () with container . bind ( Dependant ( lambda : request , scope = \"request\" ), Request ): container . execute_sync ( container . solve ( Dependant ( controller ))) This example will fail with di.exceptions.ScopeViolationError because an \"app\" scoped dependency ( conn , as requested by controller via Depends(scope=\"app\") ) depends on a request scope dependency (in framework , we specify Dependant(..., scope=\"request\" ). This is because dependencies and scopes behave much a stack and references in general purpose langauges: you can't reference a function local once you exit that function. Even if we could hold onto the value once we exit the scope, that value could be a reference to an object that already had it's destructor run, for example a database connection that was closed.","title":"Scopes"},{"location":"scopes/#local-vs-global-scopes","text":"There are two types of scopes in di : Local: localized to the current thread/coroutine via contextvars . Global: applied to the Container object itself, and hence share by any threads or coroutines that share the same Container object. You can enter a local scope via Container.enter_local_scope and a global one via Container.enter_global_scope . This can be useful to share a database connection between requests (global scope) but have each request have it's own local state (local scope), even if multiple requests are handled concurrently.","title":"Local vs. global scopes"},{"location":"sharing/","text":"Dependency sharing Often, you will have dependencies that share a sub dependency. For example, you probably only want to load your configuration from enviroment variables once and then re-use the same object in multiple dependencies. In di , we call this concept dependency sharing . How sharing works Dependencies are identfied by their callable provider. This could be the constructor for a type or an arbitrary callable encapsulated using Depends(...) . By default, dependencies are share, but this behavior can be changed on a per-dependency basis using the share=False parameter. from random import random from di import Container , Dependant , Depends def controller ( v1 : object , # no marker is equivalent to Depends(object) v2 : object = Depends ( object ), # the default value is share=True v3 : float = Depends ( random , share = False ), # but you can set share=False ) -> None : assert v1 is v2 assert v1 is not v3 and v2 is not v3 def main () -> None : container = Container () container . execute_sync ( container . solve ( Dependant ( controller ))) Sharing and scopes Dependencies are share within their scope and any innner scopes. Once a dependency's scope exits, it's share value is discareded and the next time the scope is entered a fresh value will be computed.","title":"Sharing"},{"location":"sharing/#dependency-sharing","text":"Often, you will have dependencies that share a sub dependency. For example, you probably only want to load your configuration from enviroment variables once and then re-use the same object in multiple dependencies. In di , we call this concept dependency sharing .","title":"Dependency sharing"},{"location":"sharing/#how-sharing-works","text":"Dependencies are identfied by their callable provider. This could be the constructor for a type or an arbitrary callable encapsulated using Depends(...) . By default, dependencies are share, but this behavior can be changed on a per-dependency basis using the share=False parameter. from random import random from di import Container , Dependant , Depends def controller ( v1 : object , # no marker is equivalent to Depends(object) v2 : object = Depends ( object ), # the default value is share=True v3 : float = Depends ( random , share = False ), # but you can set share=False ) -> None : assert v1 is v2 assert v1 is not v3 and v2 is not v3 def main () -> None : container = Container () container . execute_sync ( container . solve ( Dependant ( controller )))","title":"How sharing works"},{"location":"sharing/#sharing-and-scopes","text":"Dependencies are share within their scope and any innner scopes. Once a dependency's scope exits, it's share value is discareded and the next time the scope is entered a fresh value will be computed.","title":"Sharing and scopes"},{"location":"solving/","text":"Solving Solving a dependency consists of 2 steps: Build a directed acyclic graph of dependencies by inspecting sub dependencies and resolving bind overrides. Topologically sort sub dependencies and group them such that subdependencies that do not depend on eachother can be executed in parallel. Accordingly, a SolvedDependency in di corresponds of a DAG of DependencyProtocol 's and a topological sort of this DAG. You can get a SolvedDependency via Container.solve . You can then store this value or provide it to Container.execute_solved or Container.get_flat_subdependants . !! note Internally, Container.execute just calls Container.solve and Container.execute_solved . During solving, several things are checked: Dependencies must be either autowireable (valid type annotation or explicit mark via Depends(...) ) or have a bind override. The same dependency is not used twice with different scopes. However, other things are not checked and are deffered to execution time. Namely, scopes are not validated during solving . This means that you can solve a DAG including \"request\" scoped depdendencies before entering the \"request\" scope. Presolving di lets you pre-solve your dependencies so that you don't have to run the solver each time you execute. This usually comes with a huge performance boost, but only works if you have a static dependency graph (in other words, if you solve than change the DAG, e.g. by introducing a new bind, the solved version will not be updated). When you have a mostly static graph, but with a single dependency changing (e.g. an incoming web request) you can either: Pre-solve and dynamically replace the nodes in the DAG and topoligcal sort (this is not recommended). Introduce your own way to inject that dependency that preserves the DAG structure. There is an example of this in the Performance section of the Wiring docs . Getting a list of dependencies di provides a convenience function to flatten the dependency DAG into a list off all sub dependencies in Container.get_flat_subdependants . This can be used in conjunction with custom classes implementing the DependantProtocol to determine what headers or scopes an HTTP endpoint needs, amongst other uses: from typing import Any , Iterable , List from di import Container , Dependant from di.types.dependencies import DependantProtocol class Request : def __init__ ( self , scopes : Iterable [ str ]) -> None : self . scopes = set ( scopes ) class SecurityDependant ( Dependant [ bool ]): def __init__ ( self , scopes : Iterable [ str ]) -> None : self . scopes = set ( scopes ) super () . __init__ ( call = self . __call__ , scope = None , share = False ) async def __call__ ( self , request : Request ) -> bool : return self . scopes . issubset ( request . scopes ) def Security ( * scopes : str ) -> bool : return SecurityDependant ( scopes ) # type: ignore def gather_scopes ( deps : List [ DependantProtocol [ Any ]]) -> List [ str ]: scopes : List [ str ] = [] for dep in deps : if isinstance ( dep , SecurityDependant ): scopes . extend ( dep . scopes ) return scopes async def web_framework () -> None : container = Container () # note: we bind a placeholder request here so that autowiring does not complain # about not knowing how to build a Request with container . bind ( Dependant ( lambda : Request ( scopes = [])), Request ): scopes = gather_scopes ( container . solve ( Dependant ( controller )) . flat_subdependants ) assert set ( scopes ) == { \"scope1\" , \"scope2\" } valid_request = Request ( scopes = [ \"scope1\" , \"scope2\" ]) with container . bind ( Dependant ( lambda : valid_request ), Request ): await container . execute_async ( container . solve ( Dependant ( controller ))) # success invalid_request = Request ( scopes = [ \"scope1\" ]) with container . bind ( Dependant ( lambda : invalid_request ), Request ): try : await container . execute_async ( container . solve ( Dependant ( controller )) ) # fails except ValueError : pass else : raise AssertionError ( \"Using a request without the right scopes should fail\" ) def controller ( authenticated : bool = Security ( \"scope1\" , \"scope2\" )) -> None : \"\"\"This is the only piece of user code\"\"\" if not authenticated : raise ValueError","title":"Solving"},{"location":"solving/#solving","text":"Solving a dependency consists of 2 steps: Build a directed acyclic graph of dependencies by inspecting sub dependencies and resolving bind overrides. Topologically sort sub dependencies and group them such that subdependencies that do not depend on eachother can be executed in parallel. Accordingly, a SolvedDependency in di corresponds of a DAG of DependencyProtocol 's and a topological sort of this DAG. You can get a SolvedDependency via Container.solve . You can then store this value or provide it to Container.execute_solved or Container.get_flat_subdependants . !! note Internally, Container.execute just calls Container.solve and Container.execute_solved . During solving, several things are checked: Dependencies must be either autowireable (valid type annotation or explicit mark via Depends(...) ) or have a bind override. The same dependency is not used twice with different scopes. However, other things are not checked and are deffered to execution time. Namely, scopes are not validated during solving . This means that you can solve a DAG including \"request\" scoped depdendencies before entering the \"request\" scope.","title":"Solving"},{"location":"solving/#presolving","text":"di lets you pre-solve your dependencies so that you don't have to run the solver each time you execute. This usually comes with a huge performance boost, but only works if you have a static dependency graph (in other words, if you solve than change the DAG, e.g. by introducing a new bind, the solved version will not be updated). When you have a mostly static graph, but with a single dependency changing (e.g. an incoming web request) you can either: Pre-solve and dynamically replace the nodes in the DAG and topoligcal sort (this is not recommended). Introduce your own way to inject that dependency that preserves the DAG structure. There is an example of this in the Performance section of the Wiring docs .","title":"Presolving"},{"location":"solving/#getting-a-list-of-dependencies","text":"di provides a convenience function to flatten the dependency DAG into a list off all sub dependencies in Container.get_flat_subdependants . This can be used in conjunction with custom classes implementing the DependantProtocol to determine what headers or scopes an HTTP endpoint needs, amongst other uses: from typing import Any , Iterable , List from di import Container , Dependant from di.types.dependencies import DependantProtocol class Request : def __init__ ( self , scopes : Iterable [ str ]) -> None : self . scopes = set ( scopes ) class SecurityDependant ( Dependant [ bool ]): def __init__ ( self , scopes : Iterable [ str ]) -> None : self . scopes = set ( scopes ) super () . __init__ ( call = self . __call__ , scope = None , share = False ) async def __call__ ( self , request : Request ) -> bool : return self . scopes . issubset ( request . scopes ) def Security ( * scopes : str ) -> bool : return SecurityDependant ( scopes ) # type: ignore def gather_scopes ( deps : List [ DependantProtocol [ Any ]]) -> List [ str ]: scopes : List [ str ] = [] for dep in deps : if isinstance ( dep , SecurityDependant ): scopes . extend ( dep . scopes ) return scopes async def web_framework () -> None : container = Container () # note: we bind a placeholder request here so that autowiring does not complain # about not knowing how to build a Request with container . bind ( Dependant ( lambda : Request ( scopes = [])), Request ): scopes = gather_scopes ( container . solve ( Dependant ( controller )) . flat_subdependants ) assert set ( scopes ) == { \"scope1\" , \"scope2\" } valid_request = Request ( scopes = [ \"scope1\" , \"scope2\" ]) with container . bind ( Dependant ( lambda : valid_request ), Request ): await container . execute_async ( container . solve ( Dependant ( controller ))) # success invalid_request = Request ( scopes = [ \"scope1\" ]) with container . bind ( Dependant ( lambda : invalid_request ), Request ): try : await container . execute_async ( container . solve ( Dependant ( controller )) ) # fails except ValueError : pass else : raise AssertionError ( \"Using a request without the right scopes should fail\" ) def controller ( authenticated : bool = Security ( \"scope1\" , \"scope2\" )) -> None : \"\"\"This is the only piece of user code\"\"\" if not authenticated : raise ValueError","title":"Getting a list of dependencies"},{"location":"wiring/","text":"Wiring Wiring is the act of \"connecting\" together dependencies. Autowiring means that the container will detect what dependencies are required without the dependencies explicitly being registered with the container. In order to autowire dependencies, the container will inspect dependencies and find out what their dependencies are and how to construct them. This type of introspection is generally called reflection . The primary means of inspection are the standard library's inspect.signature and typing.get_type_hints . This makes autowiring compatible with a broad range of things, including: def functions Classes functools.partial binds Callable class classes or class instances (classes implementing __call__ ) Here is an example showing autowiring in action. Autowiring can work with dataclasses, even ones with a default_factory . In this example we'll load a config from the environment: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) We can also have callable classes as dependencies: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) Notice that we actually have two dependencies here: An instance of DBConn The function DBConn.__call__ , which requires an instance of DBConn Since we added a type annotation to DBConn.__call__ 's self parameter, di will know to inject the instance, but we do have to use Depends to declare the dependency explicitly since DBConn.__call__ is not a valid type annotation. import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) What makes this \"autowiring\" is that we didn't have to tell di how to construct DBConn : di detected that controller needed a DBConn and that DBConn in turn needs a Config instance. But what about situations where autowiring doesn't cut it? The most common scenario for this is when type annotations are interfaces / protocols / ABCs, not concrete implementations. This is a good general practice and is very common in larger projects. Like most other dependency injection frameworks, di provides \"binds\": a way for you to declare to the container that it should replace requests for an interface / abstraction with a concrete implementation. Binds in di are particularly powerful because the bound providers can themselves have dependencies, and those dependencies can even be autowired. For more information on binds in di , see our Binds docs. Performance Reflection (inspecting function signatures for dependencies) is slow. For this reason, di tries to avoid it as much as possible. The API is designed around isolating autowiring and execution. For example, di will let you \"solve\" a dependency into a DAG (directed acyclic graph) and a topological sort of this DAG. You can then provide this solved dependency back to di and it will execute it without any introspection or reflection . This means that if you are not dynamically changing your dependency graph, you incurr basically no cost for autowiring. For example, here is a more advanced use case where the framework takes control of binding the request itself while still allowing the di to controll the rest of the dependencies. We achieve this by: Binding a static function to provide the current request instance. Using an external method (in this case, convetxvars ) to inject this instance. This means that di does not do any reflection for each request, nor does it have to do dependency resolution. Instead, only some basic checks on scopes are done and the dependencies are executed with almost no overhead. from contextvars import ContextVar from typing import List , TypeVar import anyio from di import Container , Dependant from di.types.solved import SolvedDependency T = TypeVar ( \"T\" ) class Request : ... class RequestLog ( List [ Request ]): ... request_ctx = ContextVar [ Request ]( \"request_ctx\" ) def get_request () -> Request : return request_ctx . get () async def execute_request ( request : Request , container : Container , solved : SolvedDependency [ T ] ) -> T : async with container . enter_local_scope ( \"request\" ): token = request_ctx . set ( request ) try : return await container . execute_async ( solved ) finally : request_ctx . reset ( token ) async def framework () -> None : container = Container () request_log = RequestLog () container . bind ( Dependant ( lambda : request_log , scope = \"app\" ), RequestLog ) container . bind ( Dependant ( get_request , scope = \"request\" ), Request ) solved = container . solve ( Dependant ( controller , scope = \"request\" )) async with container . enter_global_scope ( \"app\" ): # simulate concurrent requests n_requests = 25 async with anyio . create_task_group () as tg : for _ in range ( n_requests ): tg . start_soon ( execute_request , Request (), container , solved ) # type: ignore # make sure we processed n_requests distinct requests assert len ( request_log ) == len ( set ( request_log )) == n_requests async def controller ( request : Request , request_log : RequestLog ) -> None : \"\"\"This is the only piece of user code\"\"\" request_log . append ( request )","title":"Wiring"},{"location":"wiring/#wiring","text":"Wiring is the act of \"connecting\" together dependencies. Autowiring means that the container will detect what dependencies are required without the dependencies explicitly being registered with the container. In order to autowire dependencies, the container will inspect dependencies and find out what their dependencies are and how to construct them. This type of introspection is generally called reflection . The primary means of inspection are the standard library's inspect.signature and typing.get_type_hints . This makes autowiring compatible with a broad range of things, including: def functions Classes functools.partial binds Callable class classes or class instances (classes implementing __call__ ) Here is an example showing autowiring in action. Autowiring can work with dataclasses, even ones with a default_factory . In this example we'll load a config from the environment: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) We can also have callable classes as dependencies: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) Notice that we actually have two dependencies here: An instance of DBConn The function DBConn.__call__ , which requires an instance of DBConn Since we added a type annotation to DBConn.__call__ 's self parameter, di will know to inject the instance, but we do have to use Depends to declare the dependency explicitly since DBConn.__call__ is not a valid type annotation. import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute_async ( container . solve ( Dependant ( controller ))) What makes this \"autowiring\" is that we didn't have to tell di how to construct DBConn : di detected that controller needed a DBConn and that DBConn in turn needs a Config instance. But what about situations where autowiring doesn't cut it? The most common scenario for this is when type annotations are interfaces / protocols / ABCs, not concrete implementations. This is a good general practice and is very common in larger projects. Like most other dependency injection frameworks, di provides \"binds\": a way for you to declare to the container that it should replace requests for an interface / abstraction with a concrete implementation. Binds in di are particularly powerful because the bound providers can themselves have dependencies, and those dependencies can even be autowired. For more information on binds in di , see our Binds docs.","title":"Wiring"},{"location":"wiring/#performance","text":"Reflection (inspecting function signatures for dependencies) is slow. For this reason, di tries to avoid it as much as possible. The API is designed around isolating autowiring and execution. For example, di will let you \"solve\" a dependency into a DAG (directed acyclic graph) and a topological sort of this DAG. You can then provide this solved dependency back to di and it will execute it without any introspection or reflection . This means that if you are not dynamically changing your dependency graph, you incurr basically no cost for autowiring. For example, here is a more advanced use case where the framework takes control of binding the request itself while still allowing the di to controll the rest of the dependencies. We achieve this by: Binding a static function to provide the current request instance. Using an external method (in this case, convetxvars ) to inject this instance. This means that di does not do any reflection for each request, nor does it have to do dependency resolution. Instead, only some basic checks on scopes are done and the dependencies are executed with almost no overhead. from contextvars import ContextVar from typing import List , TypeVar import anyio from di import Container , Dependant from di.types.solved import SolvedDependency T = TypeVar ( \"T\" ) class Request : ... class RequestLog ( List [ Request ]): ... request_ctx = ContextVar [ Request ]( \"request_ctx\" ) def get_request () -> Request : return request_ctx . get () async def execute_request ( request : Request , container : Container , solved : SolvedDependency [ T ] ) -> T : async with container . enter_local_scope ( \"request\" ): token = request_ctx . set ( request ) try : return await container . execute_async ( solved ) finally : request_ctx . reset ( token ) async def framework () -> None : container = Container () request_log = RequestLog () container . bind ( Dependant ( lambda : request_log , scope = \"app\" ), RequestLog ) container . bind ( Dependant ( get_request , scope = \"request\" ), Request ) solved = container . solve ( Dependant ( controller , scope = \"request\" )) async with container . enter_global_scope ( \"app\" ): # simulate concurrent requests n_requests = 25 async with anyio . create_task_group () as tg : for _ in range ( n_requests ): tg . start_soon ( execute_request , Request (), container , solved ) # type: ignore # make sure we processed n_requests distinct requests assert len ( request_log ) == len ( set ( request_log )) == n_requests async def controller ( request : Request , request_log : RequestLog ) -> None : \"\"\"This is the only piece of user code\"\"\" request_log . append ( request )","title":"Performance"}]}