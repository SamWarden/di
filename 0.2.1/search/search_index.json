{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"di : pythonic dependency injection di is a modern dependency injection system, modeled around the simplicity of FastAPI's dependency injection. Key features: Intuitive : simple things are easy, complex things are possible. Succinct : declare what you want, and di figures out how to assmble it using type annotations. Correct : tested with MyPy: value: int = Depends(returns_str) gives an error. Flexible : with no fixed scopes, di can work within any framework, web or otherwise. Lifespans : di manages lifespans for dependencies by binding them to scopes. Caching : di caches values from dependencies to avoid duplicate computation. Scalability : di executes dependencies in parallel. Performant : di moves sync dependencies into a threadpool to avoid blocking the event loop. Installation $ pip install di ---> 100% Warning This project is a work in progress. Until there is 1.X.Y release, expect breaking changes. Example In this example, we'll look at what it would take for a web framework to provide dependecy injection to it's users via di . First we declare a dependency. We'll call it Request like if it were an incoming HTTP request. This is something the web framework would provide and manage. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Next, we'll declare a controller / endpoint that uses the request. This is the only code the user would have to write. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Now we'll define what the web framework needs to do to glue everything together. This part can get a bit complex, but it's okay because it's written once, in a library. Users don't need to interact with the container or entering/exiting scopes (although they can if they want to). We start by creating a container. This would happen when the app / framework in initialized. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Next, we enter a \"request\" scope. This would happen for each incoming request. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Note that \"request\" does not have any special meaning to di : any hashable value (strings, enums, integers, etc.) will do. Frameworks using di need to establish semantic meanings for their scopes and communicate them with their users, but no changes in di are necessary to add more socpes. Now that we are in the \"request\" scope, we can bind our request instance: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Binds are always a callable. They can even have their own dependencies and declare their own scope. But in this case we want to use the same Request instance everywhere, so we define a lambda that always returns the same instance. Although not strictly necessary in this case ( Request is not a context maanger), we pass scope=\"request\" to Dependant to signify that we want teardown for that dependncy to happen when we exit the \"request\" scope. Finally, we also pass scope=\"request\" to bind() to signify that we want to revert the bind itself when we exit the \"request\" scope. We also have the option to use bind() as a context manager ( with bind(...): ), in which case the bind would be reverted as soon as we exit that context manager. Now we can execute the user's controller / endpoint: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 When we called execute() , di checked controller and saw that it needed a Request . Then it looked at the binds, found the bound provider and injected that. Project Aims This project is primarily geared for enviroments that already use inversion of control (think web frameworks, CLI frameworks or anything else where you define functions and \"it calls you\"). It particularly excels in async / concurrent environments, since the DI system has first class support for async dependencies and can gather dependencies concurrently.","title":"Intro"},{"location":"#di-pythonic-dependency-injection","text":"di is a modern dependency injection system, modeled around the simplicity of FastAPI's dependency injection. Key features: Intuitive : simple things are easy, complex things are possible. Succinct : declare what you want, and di figures out how to assmble it using type annotations. Correct : tested with MyPy: value: int = Depends(returns_str) gives an error. Flexible : with no fixed scopes, di can work within any framework, web or otherwise. Lifespans : di manages lifespans for dependencies by binding them to scopes. Caching : di caches values from dependencies to avoid duplicate computation. Scalability : di executes dependencies in parallel. Performant : di moves sync dependencies into a threadpool to avoid blocking the event loop.","title":"di: pythonic dependency injection"},{"location":"#installation","text":"$ pip install di ---> 100% Warning This project is a work in progress. Until there is 1.X.Y release, expect breaking changes.","title":"Installation"},{"location":"#example","text":"In this example, we'll look at what it would take for a web framework to provide dependecy injection to it's users via di . First we declare a dependency. We'll call it Request like if it were an incoming HTTP request. This is something the web framework would provide and manage. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Next, we'll declare a controller / endpoint that uses the request. This is the only code the user would have to write. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Now we'll define what the web framework needs to do to glue everything together. This part can get a bit complex, but it's okay because it's written once, in a library. Users don't need to interact with the container or entering/exiting scopes (although they can if they want to). We start by creating a container. This would happen when the app / framework in initialized. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Next, we enter a \"request\" scope. This would happen for each incoming request. from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Note that \"request\" does not have any special meaning to di : any hashable value (strings, enums, integers, etc.) will do. Frameworks using di need to establish semantic meanings for their scopes and communicate them with their users, but no changes in di are necessary to add more socpes. Now that we are in the \"request\" scope, we can bind our request instance: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 Binds are always a callable. They can even have their own dependencies and declare their own scope. But in this case we want to use the same Request instance everywhere, so we define a lambda that always returns the same instance. Although not strictly necessary in this case ( Request is not a context maanger), we pass scope=\"request\" to Dependant to signify that we want teardown for that dependncy to happen when we exit the \"request\" scope. Finally, we also pass scope=\"request\" to bind() to signify that we want to revert the bind itself when we exit the \"request\" scope. We also have the option to use bind() as a context manager ( with bind(...): ), in which case the bind would be reverted as soon as we exit that context manager. Now we can execute the user's controller / endpoint: from di import Container , Dependant class Request : def __init__ ( self , value : int ) -> None : self . value = value async def controller ( request : Request ) -> int : return request . value + 1 async def web_framework (): container = Container () async with container . enter_local_scope ( \"request\" ): request = Request ( 1 ) request_provider = Dependant ( lambda : request , scope = \"request\" ) container . bind ( request_provider , Request , scope = \"request\" ) res = await container . execute ( Dependant ( controller )) assert res == 2 When we called execute() , di checked controller and saw that it needed a Request . Then it looked at the binds, found the bound provider and injected that.","title":"Example"},{"location":"#project-aims","text":"This project is primarily geared for enviroments that already use inversion of control (think web frameworks, CLI frameworks or anything else where you define functions and \"it calls you\"). It particularly excels in async / concurrent environments, since the DI system has first class support for async dependencies and can gather dependencies concurrently.","title":"Project Aims"},{"location":"binds/","text":"Binds Binds provide two important functions: A way to tell the container how to assemble things that can't be autowired, for example interfaces. A way to override dependencies in tests. Every bind in di consists of: A target callable: this can be a function, an interface / protocol or a concrete class A substitute dependency: an object implementing the DependencyProtocol , usually just an instance of Dependant This means that binds are themselves dependencies: from dataclasses import dataclass from typing import List , Protocol from di import Container , Dependant class DBProtocol ( Protocol ): async def execute ( self , sql : str ) -> None : ... async def controller ( db : DBProtocol ) -> None : await db . execute ( \"SELECT *\" ) @dataclass class DBConfig : host : str = \"localhost\" class Postgres ( DBProtocol ): def __init__ ( self , config : DBConfig ) -> None : self . host = config . host self . log : List [ str ] = [] async def execute ( self , sql : str ) -> None : self . log . append ( sql ) async def framework () -> None : container = Container () async with container . enter_local_scope ( \"app\" ): with container . bind ( Dependant ( Postgres , scope = \"app\" ), DBProtocol ): # type: ignore await container . execute ( Dependant ( controller )) db = await container . execute ( Dependant ( DBProtocol )) assert isinstance ( db , Postgres ) assert db . log == [ \"SELECT *\" ] In this example we bind a concrete Postgres instance to DBProtocol , and we can see that di autowires Postgres as well!","title":"Binds"},{"location":"binds/#binds","text":"Binds provide two important functions: A way to tell the container how to assemble things that can't be autowired, for example interfaces. A way to override dependencies in tests. Every bind in di consists of: A target callable: this can be a function, an interface / protocol or a concrete class A substitute dependency: an object implementing the DependencyProtocol , usually just an instance of Dependant This means that binds are themselves dependencies: from dataclasses import dataclass from typing import List , Protocol from di import Container , Dependant class DBProtocol ( Protocol ): async def execute ( self , sql : str ) -> None : ... async def controller ( db : DBProtocol ) -> None : await db . execute ( \"SELECT *\" ) @dataclass class DBConfig : host : str = \"localhost\" class Postgres ( DBProtocol ): def __init__ ( self , config : DBConfig ) -> None : self . host = config . host self . log : List [ str ] = [] async def execute ( self , sql : str ) -> None : self . log . append ( sql ) async def framework () -> None : container = Container () async with container . enter_local_scope ( \"app\" ): with container . bind ( Dependant ( Postgres , scope = \"app\" ), DBProtocol ): # type: ignore await container . execute ( Dependant ( controller )) db = await container . execute ( Dependant ( DBProtocol )) assert isinstance ( db , Postgres ) assert db . log == [ \"SELECT *\" ] In this example we bind a concrete Postgres instance to DBProtocol , and we can see that di autowires Postgres as well!","title":"Binds"},{"location":"caching/","text":"","title":"Caching"},{"location":"callable-classes/","text":"Callable classes","title":"Callable classes"},{"location":"callable-classes/#callable-classes","text":"","title":"Callable classes"},{"location":"contributing/","text":"Developer setup This is a pure Python project and should be straightforward to set up on Linux or MacOS. We do not support Windows for development, if you use Windows you'll have to use VSCode DevContainers or a similar solution. We use Poetry for dependency management, and most of the config is the pyproject.toml . Linting is done via git hooks, managed by pre-commit . The linters may change over time, but they are configured in our pre-commit-config.yaml . Most of the setup and interaction with these systems is encapsulated in our Makefile . Project setup First, fork the repo and then clone your fork: $ git clone https://github.com/adriangb/di.git ---> 100% $ cd di Now install the project dependencies. You will need Make installed along with a compatible Python version (currently, 3.9.X). To set up the project, simply run: $ make init This will create a .venv virtualenv that you can configure your IDE to use. Running tests $ make test Tests are run with pytest, so you can also run them manually or configure your IDE to run them. The tests are stored in the tests/ directory. Running linting Linting will run automatically on every commit. To disable this, you can commit with git commit --no-verify . You can also run linting manually: $ make lint Documentation The docs are written as markdown and built with MkDocs. Both the docs and their source code are stored in the docs/ directory. To preview the docs locally as you edit them, run $ make docs-serve","title":"Contributing"},{"location":"contributing/#developer-setup","text":"This is a pure Python project and should be straightforward to set up on Linux or MacOS. We do not support Windows for development, if you use Windows you'll have to use VSCode DevContainers or a similar solution. We use Poetry for dependency management, and most of the config is the pyproject.toml . Linting is done via git hooks, managed by pre-commit . The linters may change over time, but they are configured in our pre-commit-config.yaml . Most of the setup and interaction with these systems is encapsulated in our Makefile .","title":"Developer setup"},{"location":"contributing/#project-setup","text":"First, fork the repo and then clone your fork: $ git clone https://github.com/adriangb/di.git ---> 100% $ cd di Now install the project dependencies. You will need Make installed along with a compatible Python version (currently, 3.9.X). To set up the project, simply run: $ make init This will create a .venv virtualenv that you can configure your IDE to use.","title":"Project setup"},{"location":"contributing/#running-tests","text":"$ make test Tests are run with pytest, so you can also run them manually or configure your IDE to run them. The tests are stored in the tests/ directory.","title":"Running tests"},{"location":"contributing/#running-linting","text":"Linting will run automatically on every commit. To disable this, you can commit with git commit --no-verify . You can also run linting manually: $ make lint","title":"Running linting"},{"location":"contributing/#documentation","text":"The docs are written as markdown and built with MkDocs. Both the docs and their source code are stored in the docs/ directory. To preview the docs locally as you edit them, run $ make docs-serve","title":"Documentation"},{"location":"dependants/","text":"Dependants","title":"Dependants"},{"location":"dependants/#dependants","text":"","title":"Dependants"},{"location":"dependencies/","text":"","title":"Dependencies"},{"location":"scopes/","text":"Scopes Scopes are one of the fundamental concepts in dependency injection. Some dependency injection frameworks provide fixes scopes, for example: Singleton: only one instance is created Request: in web frameworks, this could be the lifetime of a request Prototype: re-initialized every time it is needed di generalizes this concept by putting control of scopes into the hands of the users / implementers: a scope in di is identified by any hashable value (a string, enum, int, etc.) and entering / exiting scopes is handled via context managers: async with container . enter_global_scope ( \"app\" ): async with container . enter_local_scope ( 123 ): ... Scopes provide a framework for several other important features: Dependency lifespans Dependency value sharing Bind lifespans Every dependency and bind is linked to a scope. When a scope exits, all dependencies linked to it are destroyed (if they have cleanup, the cleanup is run) and their value is no longer available as a shared value. This means that dependencies scoped to an outer scope cannot depend on dependencies scoped to an inner scope: from di import Container , Dependant , Depends class Request : ... class DBConnection : def __init__ ( self , request : Request ) -> None : ... def controller ( conn : DBConnection = Depends ( scope = \"app\" )) -> None : ... async def framework () -> None : container = Container () async with container . enter_global_scope ( \"app\" ): async with container . enter_local_scope ( \"request\" ): request = Request () with container . bind ( Dependant ( lambda : request , scope = \"request\" ), Request ): await container . execute ( Dependant ( controller )) This example will fail with di.exceptions.ScopeViolationError because an \"app\" scoped dependency ( conn , as requested by controller via Depends(scope=\"app\") ) depends on a request scope dependency (in framework , we specify Dependant(..., scope=\"request\" ). This is because dependencies and scopes behave much a stack and references in general purpose langauges: you can't reference a function local once you exit that function. Even if we could hold onto the value once we exit the scope, that value could be a reference to an object that already had it's destructor run, for example a database connection that was closed. Scopes also control bind lifespans. In the example above, we established a bind using a context manager ( with container.bind(...) ). Binds also support a scope parameter. When this is passed, the bind will be cleared when the scope exits. This parameter deafaults to the current scope, but you can override it to create a bind that persists after that outlive the scope they are declared in. When using a context manager, the bind is cleared when the context manager exits, which always overrides the scope parameter because the bind's context manager necessarily exits before even the current scope is done. Local vs. global scopes There are two types of scopes in di : Local: localized to the current thread/coroutine via contextvars . Global: applied to the Container object itself, and hence shared by any threads or coroutines that share the same Container object. You can enter a local scope via Container.enter_local_scope and a global one via Container.enter_global_scope . This can be useful to share a database connection between requests (global scope) but have each request have it's own local state (local scope), even if multiple requests are handled concurrently.","title":"Scopes"},{"location":"scopes/#scopes","text":"Scopes are one of the fundamental concepts in dependency injection. Some dependency injection frameworks provide fixes scopes, for example: Singleton: only one instance is created Request: in web frameworks, this could be the lifetime of a request Prototype: re-initialized every time it is needed di generalizes this concept by putting control of scopes into the hands of the users / implementers: a scope in di is identified by any hashable value (a string, enum, int, etc.) and entering / exiting scopes is handled via context managers: async with container . enter_global_scope ( \"app\" ): async with container . enter_local_scope ( 123 ): ... Scopes provide a framework for several other important features: Dependency lifespans Dependency value sharing Bind lifespans Every dependency and bind is linked to a scope. When a scope exits, all dependencies linked to it are destroyed (if they have cleanup, the cleanup is run) and their value is no longer available as a shared value. This means that dependencies scoped to an outer scope cannot depend on dependencies scoped to an inner scope: from di import Container , Dependant , Depends class Request : ... class DBConnection : def __init__ ( self , request : Request ) -> None : ... def controller ( conn : DBConnection = Depends ( scope = \"app\" )) -> None : ... async def framework () -> None : container = Container () async with container . enter_global_scope ( \"app\" ): async with container . enter_local_scope ( \"request\" ): request = Request () with container . bind ( Dependant ( lambda : request , scope = \"request\" ), Request ): await container . execute ( Dependant ( controller )) This example will fail with di.exceptions.ScopeViolationError because an \"app\" scoped dependency ( conn , as requested by controller via Depends(scope=\"app\") ) depends on a request scope dependency (in framework , we specify Dependant(..., scope=\"request\" ). This is because dependencies and scopes behave much a stack and references in general purpose langauges: you can't reference a function local once you exit that function. Even if we could hold onto the value once we exit the scope, that value could be a reference to an object that already had it's destructor run, for example a database connection that was closed. Scopes also control bind lifespans. In the example above, we established a bind using a context manager ( with container.bind(...) ). Binds also support a scope parameter. When this is passed, the bind will be cleared when the scope exits. This parameter deafaults to the current scope, but you can override it to create a bind that persists after that outlive the scope they are declared in. When using a context manager, the bind is cleared when the context manager exits, which always overrides the scope parameter because the bind's context manager necessarily exits before even the current scope is done.","title":"Scopes"},{"location":"scopes/#local-vs-global-scopes","text":"There are two types of scopes in di : Local: localized to the current thread/coroutine via contextvars . Global: applied to the Container object itself, and hence shared by any threads or coroutines that share the same Container object. You can enter a local scope via Container.enter_local_scope and a global one via Container.enter_global_scope . This can be useful to share a database connection between requests (global scope) but have each request have it's own local state (local scope), even if multiple requests are handled concurrently.","title":"Local vs. global scopes"},{"location":"solving/","text":"Solving","title":"Solving"},{"location":"solving/#solving","text":"","title":"Solving"},{"location":"wiring/","text":"Wiring Wiring is the act of \"connecting\" together dependencies. Autowiring means that the container will detect what dependencies are required without the dependencies explicitly being registered with the container. In order to autowire dependencies, the container will inspect dependencies and find out what their dependencies are and how to construct them. This type of introspection is generally called reflection . The primary means of inspection are the standard library's inspect.signature and typing.get_type_hints . This makes autowiring compatible with a broad range of things, including: def functions Classes functools.partial binds Callable class classes or class instances (classes implementing __call__ ) Here is an example showing autowiring in action. Autowiring can work with dataclasses, even ones with a default_factory . In this example we'll load a config from the environment: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute ( Dependant ( controller )) We can also have callable classes as dependencies: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute ( Dependant ( controller )) Notice that we actually have two dependencies here: An instance of DBConn The function DBConn.__call__ , which requires an instance of DBConn Since we added a type annotation to DBConn.__call__ 's self parameter, di will know to inject the instance, but we do have to use Depends to declare the dependency explicitly since DBConn.__call__ is not a valid type annotation. import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute ( Dependant ( controller )) What makes this \"autowiring\" is that we didn't have to tell di how to construct DBConn : di detected that controller needed a DBConn and that DBConn in turn needs a Config instance. But what about situations where autowiring doesn't cut it? The most common scenario for this is when type annotations are interfaces / protocols / ABCs, not concrete implementations. This is a good general practice and is very common in larger projects. Like most other dependency injection frameworks, di provides \"binds\": a way for you to declare to the container that it should replace requests for an interface / abstraction with a concrete implementation. Binds in di are particularly powerful because the bound providers can themselves have dependencies, and those dependencies can even be autowired. For more information on binds in di , see our Binds docs. Performance Reflection (inspecting function signatures for dependencies) is slow. For this reason, di tries to avoid it as much as possible. The API is designed around isolating autowiring and execution. For example, di will let you \"solve\" a dependency into a DAG (directed acyclic graph) and a topological sort of this DAG. You can then provide this solved dependency back to di and it will execute it without any introspection or reflection . This means that if you are not dynamically changing your dependency graph, you incurr basically no cost for autowiring. For example, here is a more advanced use case where the framework takes control of binding the request itself while still allowing the di to controll the rest of the dependencies. We achieve this by: Binding a static function to provide the current request instance. Using an external method (in this case, convetxvars ) to inject this instance. This means that di does not do any reflection for each request, nor does it have to do dependency resolution. Instead, only some basic checks on scopes are done and the dependencies are executed with almost no overhead. from contextvars import ContextVar from typing import List , TypeVar import anyio from di import Container , Dependant from di.container import SolvedDependency T = TypeVar ( \"T\" ) class Request : ... class RequestLog ( List [ Request ]): ... request_ctx = ContextVar [ Request ]( \"request_ctx\" ) def get_request () -> Request : return request_ctx . get () async def execute_request ( request : Request , container : Container , solved : SolvedDependency [ T ] ) -> T : async with container . enter_local_scope ( \"request\" ): token = request_ctx . set ( request ) try : return await container . execute_solved ( solved ) finally : request_ctx . reset ( token ) async def framework () -> None : container = Container () request_log = RequestLog () container . bind ( Dependant ( lambda : request_log , scope = \"app\" ), RequestLog , scope = \"app\" ) container . bind ( Dependant ( get_request , scope = \"request\" ), Request , scope = \"app\" ) solved = container . solve ( Dependant ( controller , scope = \"request\" )) async with container . enter_global_scope ( \"app\" ): # simulate concurrent requests n_requests = 25 async with anyio . create_task_group () as tg : for _ in range ( n_requests ): tg . start_soon ( execute_request , Request (), container , solved ) # type: ignore # make sure we processed n_requests distinct requests assert len ( request_log ) == len ( set ( request_log )) == n_requests async def controller ( request : Request , request_log : RequestLog ) -> None : \"\"\"This is the only piece of user code\"\"\" request_log . append ( request )","title":"Wiring"},{"location":"wiring/#wiring","text":"Wiring is the act of \"connecting\" together dependencies. Autowiring means that the container will detect what dependencies are required without the dependencies explicitly being registered with the container. In order to autowire dependencies, the container will inspect dependencies and find out what their dependencies are and how to construct them. This type of introspection is generally called reflection . The primary means of inspection are the standard library's inspect.signature and typing.get_type_hints . This makes autowiring compatible with a broad range of things, including: def functions Classes functools.partial binds Callable class classes or class instances (classes implementing __call__ ) Here is an example showing autowiring in action. Autowiring can work with dataclasses, even ones with a default_factory . In this example we'll load a config from the environment: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute ( Dependant ( controller )) We can also have callable classes as dependencies: import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute ( Dependant ( controller )) Notice that we actually have two dependencies here: An instance of DBConn The function DBConn.__call__ , which requires an instance of DBConn Since we added a type annotation to DBConn.__call__ 's self parameter, di will know to inject the instance, but we do have to use Depends to declare the dependency explicitly since DBConn.__call__ is not a valid type annotation. import os from dataclasses import dataclass , field from di import Container , Dependant , Depends @dataclass class Config : host : str = field ( default_factory = lambda : os . getenv ( \"HOST\" , \"localhost\" )) class DBConn : def __init__ ( self , config : Config ) -> None : self . host = config . host async def __call__ ( self : \"DBConn\" ) -> \"DBConn\" : print ( \"do database stuff!\" ) return self async def controller ( conn : DBConn , conn_executed : DBConn = Depends ( DBConn . __call__ ) ) -> None : assert conn is conn_executed async def framework (): container = Container () await container . execute ( Dependant ( controller )) What makes this \"autowiring\" is that we didn't have to tell di how to construct DBConn : di detected that controller needed a DBConn and that DBConn in turn needs a Config instance. But what about situations where autowiring doesn't cut it? The most common scenario for this is when type annotations are interfaces / protocols / ABCs, not concrete implementations. This is a good general practice and is very common in larger projects. Like most other dependency injection frameworks, di provides \"binds\": a way for you to declare to the container that it should replace requests for an interface / abstraction with a concrete implementation. Binds in di are particularly powerful because the bound providers can themselves have dependencies, and those dependencies can even be autowired. For more information on binds in di , see our Binds docs.","title":"Wiring"},{"location":"wiring/#performance","text":"Reflection (inspecting function signatures for dependencies) is slow. For this reason, di tries to avoid it as much as possible. The API is designed around isolating autowiring and execution. For example, di will let you \"solve\" a dependency into a DAG (directed acyclic graph) and a topological sort of this DAG. You can then provide this solved dependency back to di and it will execute it without any introspection or reflection . This means that if you are not dynamically changing your dependency graph, you incurr basically no cost for autowiring. For example, here is a more advanced use case where the framework takes control of binding the request itself while still allowing the di to controll the rest of the dependencies. We achieve this by: Binding a static function to provide the current request instance. Using an external method (in this case, convetxvars ) to inject this instance. This means that di does not do any reflection for each request, nor does it have to do dependency resolution. Instead, only some basic checks on scopes are done and the dependencies are executed with almost no overhead. from contextvars import ContextVar from typing import List , TypeVar import anyio from di import Container , Dependant from di.container import SolvedDependency T = TypeVar ( \"T\" ) class Request : ... class RequestLog ( List [ Request ]): ... request_ctx = ContextVar [ Request ]( \"request_ctx\" ) def get_request () -> Request : return request_ctx . get () async def execute_request ( request : Request , container : Container , solved : SolvedDependency [ T ] ) -> T : async with container . enter_local_scope ( \"request\" ): token = request_ctx . set ( request ) try : return await container . execute_solved ( solved ) finally : request_ctx . reset ( token ) async def framework () -> None : container = Container () request_log = RequestLog () container . bind ( Dependant ( lambda : request_log , scope = \"app\" ), RequestLog , scope = \"app\" ) container . bind ( Dependant ( get_request , scope = \"request\" ), Request , scope = \"app\" ) solved = container . solve ( Dependant ( controller , scope = \"request\" )) async with container . enter_global_scope ( \"app\" ): # simulate concurrent requests n_requests = 25 async with anyio . create_task_group () as tg : for _ in range ( n_requests ): tg . start_soon ( execute_request , Request (), container , solved ) # type: ignore # make sure we processed n_requests distinct requests assert len ( request_log ) == len ( set ( request_log )) == n_requests async def controller ( request : Request , request_log : RequestLog ) -> None : \"\"\"This is the only piece of user code\"\"\" request_log . append ( request )","title":"Performance"}]}